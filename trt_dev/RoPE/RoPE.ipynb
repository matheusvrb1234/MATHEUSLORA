{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0311d6f0",
   "metadata": {},
   "source": [
    "# RoPE with TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27617192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cuda import cudart\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import tensorrt as trt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1626cae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0a0+4136153\n",
      "TensorRT version: 8.6.1\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version: \" + torch.__version__)\n",
    "print(\"TensorRT version: \" + trt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c13142a",
   "metadata": {},
   "source": [
    "## 0. Generate input and data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0facafb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict()\n",
    "\n",
    "batch_size, seq_len, hidden_size = 4, 45, 4096\n",
    "intermediate_size = 11008\n",
    "num_attention_heads = 32\n",
    "num_key_value_heads = 32\n",
    "max_position_embeddings = 2048\n",
    "rope_theta = 10000.0\n",
    "\n",
    "config[\"hidden_size\"] = hidden_size\n",
    "config[\"intermediate_size\"] = intermediate_size\n",
    "config[\"num_heads\"] = num_attention_heads\n",
    "config[\"head_dim\"] = config[\"hidden_size\"] // config[\"num_heads\"]\n",
    "config[\"num_key_value_heads\"] = num_key_value_heads\n",
    "config[\"num_key_value_groups\"] = config[\"num_heads\"] // config[\"num_key_value_heads\"]\n",
    "config[\"max_position_embeddings\"] = max_position_embeddings\n",
    "config[\"rope_theta\"] = rope_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbe3f774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : torch.Size([4, 45, 4096])\n",
      "attention_mask : torch.Size([4, 1, 45, 45])\n",
      "position_ids : torch.Size([45])\n",
      "position_ids : torch.Size([4, 45])\n"
     ]
    }
   ],
   "source": [
    "data = torch.ones(batch_size, seq_len, hidden_size)\n",
    "attention_mask = torch.ones(batch_size, 1, seq_len, seq_len)\n",
    "print(\"data : \" + str(data.shape))\n",
    "print(\"attention_mask : \" + str(attention_mask.shape))\n",
    "position_ids = torch.arange(0, seq_len)\n",
    "print(\"position_ids : \" + str(position_ids.shape))\n",
    "position_ids = position_ids.repeat(batch_size, 1)\n",
    "print(\"position_ids : \" + str(position_ids.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c91d9c8",
   "metadata": {},
   "source": [
    "## 1. RoPE with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "922cff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlamaRotaryEmbedding(torch.nn.Module):\n",
    "    def __init__(self, dim, max_position_embeddings=2048, base=10000, device=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.base = base\n",
    "        inv_freq = 1.0 / (self.base ** (torch.arange(0, self.dim, 2).float().to(device) / self.dim))\n",
    "        \n",
    "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
    "        \n",
    "        t = torch.arange(max_position_embeddings, device=device, dtype=self.inv_freq.dtype)\n",
    "        # Outer Product: outer(A, B)\n",
    "        freqs = torch.einsum(\"i,j->ij\", t, self.inv_freq)\n",
    "        # Different from paper, but it uses a different permutation in order to obtain the same calculation\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        self.register_buffer(\"cos_cached\", emb.cos()[None, None, :, :].to(torch.get_default_dtype()), persistent=False)\n",
    "        self.register_buffer(\"sin_cached\", emb.sin()[None, None, :, :].to(torch.get_default_dtype()), persistent=False)\n",
    "        \n",
    "    def rotate_half(self, x):\n",
    "        \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
    "        x1 = x[..., : x.shape[-1] // 2]\n",
    "        x2 = x[..., x.shape[-1] // 2 :]\n",
    "        return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "    def forward(self, q, k, v, position_ids, seq_len=None):\n",
    "        # v: [bs, num_attention_heads, seq_len, head_size]\n",
    "        cos = self.cos_cached[:, :, :seq_len, ...].to(dtype=v.dtype)\n",
    "        sin = self.sin_cached[:, :, :seq_len, ...].to(dtype=v.dtype)\n",
    "        cos = cos.squeeze(1).squeeze(0)  # [seq_len, dim]\n",
    "        sin = sin.squeeze(1).squeeze(0)  # [seq_len, dim]\n",
    "        cos = cos[position_ids].unsqueeze(1)  # [bs, 1, seq_len, dim]\n",
    "        sin = sin[position_ids].unsqueeze(1)  # [bs, 1, seq_len, dim]\n",
    "        \n",
    "        # The first two dimensions of cos and sin are always 1, so we can `squeeze` them.\n",
    "        print(\"Pytorch RoPE - forwarding: \" + str(cos))\n",
    "        q_embed = (q * cos) + (self.rotate_half(q) * sin)\n",
    "        k_embed = (k * cos) + (self.rotate_half(k) * sin)\n",
    "        return q_embed, k_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f28d1",
   "metadata": {},
   "source": [
    "## 2. Test Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c825eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input query_states: after reshape torch.Size([4, 32, 45, 128])\n",
      "tensor([[[-0.7269, -0.0775, -0.7819,  ..., -0.4893, -0.1463, -0.1300],\n",
      "         [-0.7269, -0.0775, -0.7819,  ..., -0.4893, -0.1463, -0.1300],\n",
      "         [-0.7269, -0.0775, -0.7819,  ..., -0.4893, -0.1463, -0.1300],\n",
      "         ...,\n",
      "         [-0.7269, -0.0775, -0.7819,  ..., -0.4893, -0.1463, -0.1300],\n",
      "         [-0.7269, -0.0775, -0.7819,  ..., -0.4893, -0.1463, -0.1300],\n",
      "         [-0.7269, -0.0775, -0.7819,  ..., -0.4893, -0.1463, -0.1300]],\n",
      "\n",
      "        [[-0.8873, -1.1440, -0.9657,  ...,  0.4321, -0.2121, -0.6659],\n",
      "         [-0.8873, -1.1440, -0.9657,  ...,  0.4321, -0.2121, -0.6659],\n",
      "         [-0.8873, -1.1440, -0.9657,  ...,  0.4321, -0.2121, -0.6659],\n",
      "         ...,\n",
      "         [-0.8873, -1.1440, -0.9657,  ...,  0.4321, -0.2121, -0.6659],\n",
      "         [-0.8873, -1.1440, -0.9657,  ...,  0.4321, -0.2121, -0.6659],\n",
      "         [-0.8873, -1.1440, -0.9657,  ...,  0.4321, -0.2121, -0.6659]],\n",
      "\n",
      "        [[ 0.4959, -0.2269, -0.1815,  ...,  0.1882,  0.2129,  0.2076],\n",
      "         [ 0.4959, -0.2269, -0.1815,  ...,  0.1882,  0.2129,  0.2076],\n",
      "         [ 0.4959, -0.2269, -0.1815,  ...,  0.1882,  0.2129,  0.2076],\n",
      "         ...,\n",
      "         [ 0.4959, -0.2269, -0.1815,  ...,  0.1882,  0.2129,  0.2076],\n",
      "         [ 0.4959, -0.2269, -0.1815,  ...,  0.1882,  0.2129,  0.2076],\n",
      "         [ 0.4959, -0.2269, -0.1815,  ...,  0.1882,  0.2129,  0.2076]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0637, -1.0732, -0.0501,  ..., -0.7559, -0.0994, -0.2664],\n",
      "         [ 0.0637, -1.0732, -0.0501,  ..., -0.7559, -0.0994, -0.2664],\n",
      "         [ 0.0637, -1.0732, -0.0501,  ..., -0.7559, -0.0994, -0.2664],\n",
      "         ...,\n",
      "         [ 0.0637, -1.0732, -0.0501,  ..., -0.7559, -0.0994, -0.2664],\n",
      "         [ 0.0637, -1.0732, -0.0501,  ..., -0.7559, -0.0994, -0.2664],\n",
      "         [ 0.0637, -1.0732, -0.0501,  ..., -0.7559, -0.0994, -0.2664]],\n",
      "\n",
      "        [[-0.1941, -0.4616, -0.7177,  ...,  0.0067,  0.1523, -0.8723],\n",
      "         [-0.1941, -0.4616, -0.7177,  ...,  0.0067,  0.1523, -0.8723],\n",
      "         [-0.1941, -0.4616, -0.7177,  ...,  0.0067,  0.1523, -0.8723],\n",
      "         ...,\n",
      "         [-0.1941, -0.4616, -0.7177,  ...,  0.0067,  0.1523, -0.8723],\n",
      "         [-0.1941, -0.4616, -0.7177,  ...,  0.0067,  0.1523, -0.8723],\n",
      "         [-0.1941, -0.4616, -0.7177,  ...,  0.0067,  0.1523, -0.8723]],\n",
      "\n",
      "        [[ 0.2156,  0.2869,  1.1822,  ..., -0.6797, -0.3024,  0.0535],\n",
      "         [ 0.2156,  0.2869,  1.1822,  ..., -0.6797, -0.3024,  0.0535],\n",
      "         [ 0.2156,  0.2869,  1.1822,  ..., -0.6797, -0.3024,  0.0535],\n",
      "         ...,\n",
      "         [ 0.2156,  0.2869,  1.1822,  ..., -0.6797, -0.3024,  0.0535],\n",
      "         [ 0.2156,  0.2869,  1.1822,  ..., -0.6797, -0.3024,  0.0535],\n",
      "         [ 0.2156,  0.2869,  1.1822,  ..., -0.6797, -0.3024,  0.0535]]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Prepare Pytorch Testing Parameter\n",
    "q_proj = nn.Linear(config[\"hidden_size\"], config[\"num_heads\"] * config[\"hidden_size\"] // config[\"num_heads\"], bias=False)\n",
    "k_proj = nn.Linear(config[\"hidden_size\"], config[\"num_key_value_heads\"] * config[\"head_dim\"], bias=False)\n",
    "v_proj = nn.Linear(config[\"hidden_size\"], config[\"num_key_value_heads\"] * config[\"head_dim\"], bias=False)\n",
    "\n",
    "query_states = q_proj(data)\n",
    "key_states = k_proj(data)\n",
    "value_states = v_proj(data)\n",
    "\n",
    "bsz, q_len, _ = data.size()\n",
    "\n",
    "# reshape\n",
    "query_states = query_states.view(bsz, q_len, config[\"num_heads\"], config[\"head_dim\"]).transpose(1, 2)\n",
    "key_states = key_states.view(bsz, q_len, config[\"num_key_value_heads\"], config[\"head_dim\"]).transpose(1, 2)\n",
    "value_states = value_states.view(bsz, q_len, config[\"num_key_value_heads\"], config[\"head_dim\"]).transpose(1, 2)\n",
    "print(\"Input query_states: after reshape \" + str(query_states.shape))\n",
    "print(query_states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "895de436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch RoPE - forwarding: tensor([[[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.5403,  0.6479,  0.7318,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [-0.4161, -0.1604,  0.0709,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [-0.4000,  0.2398,  0.9968,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.5551,  0.8949,  0.6752,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.9998,  0.9198, -0.0086,  ...,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.5403,  0.6479,  0.7318,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [-0.4161, -0.1604,  0.0709,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [-0.4000,  0.2398,  0.9968,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.5551,  0.8949,  0.6752,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.9998,  0.9198, -0.0086,  ...,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.5403,  0.6479,  0.7318,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [-0.4161, -0.1604,  0.0709,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [-0.4000,  0.2398,  0.9968,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.5551,  0.8949,  0.6752,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.9998,  0.9198, -0.0086,  ...,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.5403,  0.6479,  0.7318,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [-0.4161, -0.1604,  0.0709,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [-0.4000,  0.2398,  0.9968,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.5551,  0.8949,  0.6752,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.9998,  0.9198, -0.0086,  ...,  1.0000,  1.0000,  1.0000]]]],\n",
      "       device='cuda:0')\n",
      "output_query_states: torch.Size([4, 32, 45, 128])\n"
     ]
    }
   ],
   "source": [
    "model = LlamaRotaryEmbedding(dim=config[\"hidden_size\"] // config[\"num_heads\"],\n",
    "                             max_position_embeddings = config[\"max_position_embeddings\"],\n",
    "                             base = config[\"rope_theta\"])\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "data_D = data.to(device)\n",
    "attention_mask_D = attention_mask.to(device)\n",
    "position_ids_D = position_ids.to(device)\n",
    "\n",
    "query_states_D = query_states.to(device)\n",
    "key_states_D = key_states.to(device)\n",
    "value_states_D = value_states.to(device)\n",
    "\n",
    "output_query_states, output_key_states = model(query_states_D, key_states_D, value_states_D, position_ids_D, seq_len=q_len)\n",
    "\n",
    "print(\"output_query_states: \" + str(output_query_states.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88cc373d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7269, -0.0775, -0.7819,  ..., -0.4893, -0.1463, -0.1300],\n",
       "         [-0.5390, -0.8500, -0.8107,  ..., -0.4892, -0.1461, -0.1299],\n",
       "         [ 0.1444, -1.0239, -0.4045,  ..., -0.4892, -0.1460, -0.1298],\n",
       "         ...,\n",
       "         [ 0.4500,  1.0007, -0.8073,  ..., -0.4874, -0.1385, -0.1255],\n",
       "         [-0.2589,  0.3992, -0.7861,  ..., -0.4873, -0.1383, -0.1254],\n",
       "         [-0.7298, -0.4834, -0.3431,  ..., -0.4873, -0.1381, -0.1253]],\n",
       "\n",
       "        [[-0.8873, -1.1440, -0.9657,  ...,  0.4321, -0.2121, -0.6659],\n",
       "         [-0.6318, -0.1051, -0.4665,  ...,  0.4318, -0.2120, -0.6659],\n",
       "         [ 0.2046,  1.0079,  0.2829,  ...,  0.4316, -0.2119, -0.6659],\n",
       "         ...,\n",
       "         [ 0.5209, -1.0852, -0.9346,  ...,  0.4223, -0.2067, -0.6659],\n",
       "         [-0.3420, -1.3965, -0.3922,  ...,  0.4220, -0.2066, -0.6659],\n",
       "         [-0.8904, -0.7245,  0.3607,  ...,  0.4218, -0.2065, -0.6659]],\n",
       "\n",
       "        [[ 0.4959, -0.2269, -0.1815,  ...,  0.1882,  0.2129,  0.2076],\n",
       "         [ 0.7157, -0.0068, -0.3643,  ...,  0.1884,  0.2130,  0.2076],\n",
       "         [ 0.2775,  0.2180, -0.3517,  ...,  0.1885,  0.2130,  0.2076],\n",
       "         ...,\n",
       "         [-0.6860, -0.2330, -0.2080,  ...,  0.1935,  0.2134,  0.2075],\n",
       "         [-0.1673, -0.2851, -0.3731,  ...,  0.1936,  0.2134,  0.2075],\n",
       "         [ 0.5052, -0.1364, -0.3381,  ...,  0.1937,  0.2134,  0.2075]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0637, -1.0732, -0.0501,  ..., -0.7559, -0.0994, -0.2664],\n",
       "         [-0.2395, -1.0611, -0.4876,  ..., -0.7560, -0.0993, -0.2664],\n",
       "         [-0.3225, -0.3018, -0.6635,  ..., -0.7560, -0.0992, -0.2664],\n",
       "         ...,\n",
       "         [ 0.2729,  0.2088, -0.1026,  ..., -0.7572, -0.0963, -0.2665],\n",
       "         [ 0.3062, -0.7460, -0.5219,  ..., -0.7572, -0.0962, -0.2665],\n",
       "         [ 0.0579, -1.1755, -0.6612,  ..., -0.7572, -0.0962, -0.2665]],\n",
       "\n",
       "        [[-0.1941, -0.4616, -0.7177,  ...,  0.0067,  0.1523, -0.8723],\n",
       "         [-0.5795, -0.6414, -0.8936,  ...,  0.0067,  0.1522, -0.8722],\n",
       "         [-0.4321, -0.3695, -0.5902,  ...,  0.0068,  0.1522, -0.8722],\n",
       "         ...,\n",
       "         [ 0.5946,  0.3256, -0.7584,  ...,  0.0069,  0.1508, -0.8693],\n",
       "         [ 0.3614, -0.2125, -0.8834,  ...,  0.0069,  0.1507, -0.8693],\n",
       "         [-0.2041, -0.6009, -0.5344,  ...,  0.0069,  0.1507, -0.8692]],\n",
       "\n",
       "        [[ 0.2156,  0.2869,  1.1822,  ..., -0.6797, -0.3024,  0.0535],\n",
       "         [ 0.4715, -0.0572,  0.9220,  ..., -0.6798, -0.3024,  0.0535],\n",
       "         [ 0.2939, -0.3611,  0.1671,  ..., -0.6800, -0.3024,  0.0534],\n",
       "         ...,\n",
       "         [-0.4729,  0.3787,  1.1851,  ..., -0.6853, -0.3028,  0.0507],\n",
       "         [-0.2312,  0.3992,  0.8598,  ..., -0.6854, -0.3028,  0.0507],\n",
       "         [ 0.2230,  0.1386,  0.0733,  ..., -0.6856, -0.3028,  0.0506]]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_query_states[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f2d6d",
   "metadata": {},
   "source": [
    "## 3. RoPE with TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c406b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq length is not specified, since it is a dynamic size\n",
    "def trt_create(batch_size, num_attention_heads, dim, max_position_embeddings, base):\n",
    "    # Config TensorRT Logger, Builder, Network\n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    builder = trt.Builder(logger)\n",
    "\n",
    "    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "    config = builder.create_builder_config()\n",
    "\n",
    "    # inputs: Q, K with dynamic seq_len (seq_len_mask: provide dynamic shape)\n",
    "    query_states = network.add_input('query_states', trt.DataType.FLOAT, (batch_size, num_attention_heads, -1, dim))\n",
    "    key_states = network.add_input('key_states', trt.DataType.FLOAT, (batch_size, num_attention_heads, -1, dim))\n",
    "    seq_len_mask = network.add_input('seq_len_mask', trt.DataType.FLOAT, (-1, dim))\n",
    "    \n",
    "    # dynamic shape optimization\n",
    "    profile = builder.create_optimization_profile();\n",
    "    profile.set_shape(\"query_states\", \n",
    "                      (batch_size, num_attention_heads, 1, dim), \n",
    "                      (batch_size, num_attention_heads, 45, dim), \n",
    "                      (batch_size, num_attention_heads, 1024, dim))\n",
    "    profile.set_shape(\"key_states\",  \n",
    "                      (batch_size, num_attention_heads, 1, dim), \n",
    "                      (batch_size, num_attention_heads, 45, dim), \n",
    "                      (batch_size, num_attention_heads, 1024, dim))\n",
    "    profile.set_shape(\"seq_len_mask\", (1, dim), (45, dim), (1024, dim)) \n",
    "    \n",
    "    config.add_optimization_profile(profile)\n",
    "    \n",
    "    print(\"- 0) input: Q, K, seq_len_mask shape :\")\n",
    "    print(query_states.shape, key_states.shape, seq_len_mask.shape)\n",
    "\n",
    "    # 1. Precompute sin & cos cache with max_position_embeddings\n",
    "    print(\"- 1) Precompute sin & cos cache:\")\n",
    "    # Build the theta parameter\n",
    "    # According to the formula theta_i = 10000^(-2(i-1)/dim) for i = [1, 2, ... dim/2]\n",
    "    # Shape: (Head_Dim / 2) = (64,)\n",
    "    theta_numerator = np.arange(0, dim, 2).astype('float32')\n",
    "    # Shape: (Head_Dim / 2) = (64,)\n",
    "    theta = 1.0 / (base ** (theta_numerator / dim)) # (dim / 2)\n",
    "    # Construct the positions (the \"m\" parameter)\n",
    "    # Shape: (Max_Position_Embeddings) = (2048,) \n",
    "    m = np.arange(max_position_embeddings).astype('float32')\n",
    "    # Multiply each theta by each position using the outer product.\n",
    "    # Shape: (Max_Position_Embeddings) outer_product* (Head_Dim / 2) -> (Max_Position_Embeddings, Head_Dim / 2) = (2048, 64)\n",
    "    freqs = np.outer(m, theta)\n",
    "    # Different from paper, but it uses a different permutation in order to obtain the same calculation\n",
    "    # emb Shape: (2048, 128)\n",
    "    emb = np.concatenate((freqs, freqs), axis=-1)\n",
    "    \n",
    "    # 2. Convert to cos, sin cache = (2048, 128)\n",
    "    cos_cached_np = np.cos(emb) #[None, None, :, :]\n",
    "    sin_cached_np = np.sin(emb) #[None, None, :, :]\n",
    "    cached_shape = list(cos_cached_np.shape)\n",
    "    \n",
    "    cos_cached_layer = network.add_constant(shape=cached_shape, weights=trt.Weights(cos_cached_np))\n",
    "    sin_cached_layer = network.add_constant(shape=cached_shape, weights=trt.Weights(sin_cached_np))\n",
    "   \n",
    "    print(\"- 2) cos, sin cached layer shape :\")\n",
    "    print(cos_cached_layer.get_output(0).shape)\n",
    "    \n",
    "    # 3. Dynamic Slicing: to fetch cos_cache by seq_len :  e.g. [2048, 128] -> [seq_len, 128]\n",
    "    # See detail https://github.com/NVIDIA/TensorRT/issues/2282\n",
    "    \n",
    "    # Fill in start, shape, and stride with some sane defaults.\n",
    "    # Later, we'll replace these with input tensors to make the slice dynamic.\n",
    "    cos_cached_slice_layer = network.add_slice(cos_cached_layer.get_output(0), start=(0, 0), shape=(32, dim), stride=(1, 1))\n",
    "    sin_cached_slice_layer = network.add_slice(sin_cached_layer.get_output(0), start=(0, 0), shape=(32, dim), stride=(1, 1))\n",
    "    \n",
    "    # Get the seq_len shape from IShapeLayer: (-1, 128)\n",
    "    seq_len_mask_shape = network.add_shape(seq_len_mask)\n",
    "    \n",
    "    # Now that we know the seq_len_mask shape, let's add an input tensor for `shape`, which is at index 2.\n",
    "    # Refer to the API documentation for details:\n",
    "    # https://docs.nvidia.com/deeplearning/tensorrt/api/python_api/infer/Graph/Layers.html?highlight=islicelayer#tensorrt.ISliceLayer.set_input.\n",
    "    cos_cached_slice_layer.set_input(2, seq_len_mask_shape.get_output(0))\n",
    "    sin_cached_slice_layer.set_input(2, seq_len_mask_shape.get_output(0))\n",
    "    \n",
    "    print(\"- 3) cos_cached_slice_layer shape :\")\n",
    "    print(cos_cached_slice_layer.get_output(0).shape)\n",
    "    \n",
    "    # 4. repeat the cos , sin cache with batch_size (new dimension) = [seq_len, 128] -> [batch_size, seq_len, 128]\n",
    "    print(\"- 4-1) cos_cached_slice_shuffle_layer shape :\")\n",
    "    cos_cached_slice_shuffle_layer = network.add_shuffle(cos_cached_slice_layer.get_output(0))\n",
    "    sin_cached_slice_shuffle_layer = network.add_shuffle(sin_cached_slice_layer.get_output(0))\n",
    "    \n",
    "    cos_cached_slice_shuffle_layer.reshape_dims = trt.Dims([1, 1, -1, dim])\n",
    "    sin_cached_slice_shuffle_layer.reshape_dims = trt.Dims([1, 1, -1, dim])\n",
    "    \n",
    "    \n",
    "    print(cos_cached_slice_shuffle_layer.get_output(0).shape)\n",
    "    print(\"- 4-2) cos_cached_slice_repeat_layer shape :\")\n",
    "    \n",
    "    cos_cached_slice_repeat_layer = network.add_concatenation([cos_cached_slice_shuffle_layer.get_output(0), \n",
    "                                                               cos_cached_slice_shuffle_layer.get_output(0), \n",
    "                                                               cos_cached_slice_shuffle_layer.get_output(0), \n",
    "                                                               cos_cached_slice_shuffle_layer.get_output(0)])\n",
    "    sin_cached_slice_repeat_layer = network.add_concatenation([sin_cached_slice_shuffle_layer.get_output(0), \n",
    "                                                               sin_cached_slice_shuffle_layer.get_output(0), \n",
    "                                                               sin_cached_slice_shuffle_layer.get_output(0), \n",
    "                                                               sin_cached_slice_shuffle_layer.get_output(0)])\n",
    "    \n",
    "    cos_cached_slice_repeat_layer.axis = 0\n",
    "    sin_cached_slice_repeat_layer.axis = 0\n",
    "    \n",
    "    print(cos_cached_slice_repeat_layer.get_output(0).shape)\n",
    "    \n",
    "    # 5. rotate_half of Q, K tensor:\n",
    "    print(\"- 5) rotate_half of Q, K shape : (slice half / negative x2 / concat(-x2, x1) )\")\n",
    "    # 5-0) get rotate_half shape \n",
    "    q_state_shape = network.add_shape(query_states)\n",
    "    q_state_shape_divisor = network.add_constant(shape=(4,), weights=np.array([1, 1, 1, 2], dtype=np.int32))\n",
    "    rotate_half_shape = network.add_elementwise(q_state_shape.get_output(0), \n",
    "                                                q_state_shape_divisor.get_output(0), \n",
    "                                                trt.ElementWiseOperation.DIV)\n",
    "    # 5-1) slice half tensor\n",
    "    rotate_half_q1 = network.add_slice(query_states, start=(0, 0, 0, 0), \n",
    "                                       shape=(4, 1, 64, 64), \n",
    "                                       stride=(1, 1, 1, 1))\n",
    "    rotate_half_q2 = network.add_slice(query_states, start=(0, 0, 0, 64), \n",
    "                                       shape=(4, 1, 64, 64), \n",
    "                                       stride=(1, 1, 1, 1))\n",
    "    rotate_half_k1 = network.add_slice(key_states, start=(0, 0, 0, 0), \n",
    "                                       shape=(4, 1, 64, 64), \n",
    "                                       stride=(1, 1, 1, 1))\n",
    "    rotate_half_k2 = network.add_slice(key_states, start=(0, 0, 0, 64), \n",
    "                                       shape=(4, 1, 64, 64), \n",
    "                                       stride=(1, 1, 1, 1))\n",
    "    rotate_half_q1.set_input(2, rotate_half_shape.get_output(0))\n",
    "    rotate_half_q2.set_input(2, rotate_half_shape.get_output(0))\n",
    "    rotate_half_k1.set_input(2, rotate_half_shape.get_output(0))\n",
    "    rotate_half_k2.set_input(2, rotate_half_shape.get_output(0))\n",
    "    print(rotate_half_q2.get_output(0).shape)\n",
    "    \n",
    "    # 5-2) negative x2\n",
    "    rotate_half_q2_negative = network.add_unary(rotate_half_q2.get_output(0), op=trt.UnaryOperation.NEG)\n",
    "    rotate_half_k2_negative = network.add_unary(rotate_half_k2.get_output(0), op=trt.UnaryOperation.NEG)\n",
    "    print(rotate_half_q2_negative.get_output(0).shape)\n",
    "    \n",
    "    # 5-3) concat (-x2, x1)\n",
    "    rotate_half_q2_negative_concat_q1 = network.add_concatenation([rotate_half_q2_negative.get_output(0),\n",
    "                                                                   rotate_half_q1.get_output(0)])\n",
    "    rotate_half_k2_negative_concat_k1 = network.add_concatenation([rotate_half_k2_negative.get_output(0),\n",
    "                                                                   rotate_half_k1.get_output(0)])\n",
    "    rotate_half_q2_negative_concat_q1.axis = 3\n",
    "    rotate_half_k2_negative_concat_k1.axis = 3\n",
    "    \n",
    "    print(rotate_half_q2_negative_concat_q1.get_output(0).shape)\n",
    "    \n",
    "    # 6. Output: Matrix Multiply of Q * cos + rotate_half(Q) * sin\n",
    "    print(\"- 6) Output: Q_embed = Q * cos + rotate_half(Q) * sin\")\n",
    "    q_cos = network.add_einsum(inputs=[query_states, cos_cached_slice_repeat_layer.get_output(0)], equation=\"ijkl,ijkl->ijkl\")\n",
    "    q_sin = network.add_einsum(inputs=[rotate_half_q2_negative_concat_q1.get_output(0), \n",
    "                                       sin_cached_slice_repeat_layer.get_output(0)], equation=\"ijkl,ijkl->ijkl\")\n",
    "    q_embed = network.add_elementwise(q_cos.get_output(0), q_sin.get_output(0), op=trt.ElementWiseOperation.SUM)\n",
    "    \n",
    "    k_cos = network.add_einsum(inputs=[key_states, cos_cached_slice_repeat_layer.get_output(0)], equation=\"ijkl,ijkl->ijkl\")\n",
    "    k_sin = network.add_einsum(inputs=[rotate_half_k2_negative_concat_k1.get_output(0), \n",
    "                                       sin_cached_slice_repeat_layer.get_output(0)], equation=\"ijkl,ijkl->ijkl\")\n",
    "    k_embed = network.add_elementwise(k_cos.get_output(0), k_sin.get_output(0), op=trt.ElementWiseOperation.SUM)\n",
    "    \n",
    "    print(q_embed.get_output(0).shape)\n",
    "    print(k_embed.get_output(0).shape)\n",
    "    \n",
    "    print(\"- 7) check seq_len_mask shape :\")\n",
    "    print(seq_len_mask.shape)\n",
    "    \n",
    "    network.mark_output(q_embed.get_output(0))\n",
    "    network.mark_output(k_embed.get_output(0))\n",
    "\n",
    "    engineString = builder.build_serialized_network(network, config)\n",
    "    \n",
    "    return engineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22183f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 0) input: Q, K, seq_len_mask shape :\n",
      "(4, 32, -1, 128) (4, 32, -1, 128) (-1, 128)\n",
      "- 1) Precompute sin & cos cache:\n",
      "- 2) cos, sin cached layer shape :\n",
      "(2048, 128)\n",
      "- 3) cos_cached_slice_layer shape :\n",
      "(-1, 128)\n",
      "- 4-1) cos_cached_slice_shuffle_layer shape :\n",
      "(1, 1, -1, 128)\n",
      "- 4-2) cos_cached_slice_repeat_layer shape :\n",
      "(4, 1, -1, 128)\n",
      "- 5) rotate_half of Q, K shape : (slice half / negative x2 / concat(-x2, x1) )\n",
      "(4, 32, -1, 64)\n",
      "(4, 32, -1, 64)\n",
      "(4, 32, -1, 128)\n",
      "- 6) Output: Q_embed = Q * cos + rotate_half(Q) * sin\n",
      "(4, 32, -1, 128)\n",
      "(4, 32, -1, 128)\n",
      "- 7) check seq_len_mask shape :\n",
      "(-1, 128)\n"
     ]
    }
   ],
   "source": [
    "trt_engineStr = trt_create(batch_size = batch_size, \n",
    "                           num_attention_heads = config[\"num_heads\"],\n",
    "                           dim = config[\"head_dim\"],\n",
    "                           max_position_embeddings = config[\"max_position_embeddings\"],\n",
    "                           base = config[\"rope_theta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7f40d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_inference(batch_size, num_attention_heads, dim, engineString, q_state, k_state, seq_len_mask): \n",
    "\n",
    "    print(\"Runtime\")\n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    engine = trt.Runtime(logger).deserialize_cuda_engine(engineString)\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    # dynamic shape configure\n",
    "    print(\"Set input shape: query_states\")\n",
    "    #context.active_optimization_profile = 0\n",
    "    \n",
    "    q_shape = context.get_binding_shape(0)\n",
    "    print(q_shape)\n",
    "    context.set_input_shape(\"query_states\", (batch_size, num_attention_heads, seq_len, dim))\n",
    "    context.set_binding_shape(0, (batch_size, num_attention_heads, seq_len, dim))\n",
    "\n",
    "    print(\"Set input shape: key_states\")\n",
    "    k_shape = context.get_binding_shape(1)\n",
    "    print(k_shape)\n",
    "    context.set_input_shape(\"key_states\", (batch_size, num_attention_heads, seq_len, dim))\n",
    "    context.set_binding_shape(1, (batch_size, num_attention_heads, seq_len, dim))\n",
    "    \n",
    "    print(\"Set input shape: seq_len_mask\")\n",
    "    mask_shape = context.get_binding_shape(2)\n",
    "    print(mask_shape)\n",
    "    context.set_input_shape(\"seq_len_mask\", (seq_len, dim))\n",
    "    context.set_binding_shape(2, (seq_len, dim))\n",
    "    \n",
    "    print(\"Set input shape completed\")\n",
    "\n",
    "    q_state_data = np.array(q_state)\n",
    "    k_state_data = np.array(k_state)\n",
    "    seq_len_mask_data = np.array(seq_len_mask)\n",
    "\n",
    "    _, stream = cudart.cudaStreamCreate()\n",
    "#     print(\"Reshaping\")\n",
    "\n",
    "    inputH0 = np.ascontiguousarray(q_state_data.reshape(-1))\n",
    "    inputH1 = np.ascontiguousarray(k_state_data.reshape(-1))\n",
    "    inputH2 = np.ascontiguousarray(seq_len_mask_data.reshape(-1))\n",
    "    outputH0 = np.empty(context.get_binding_shape(3), dtype=trt.nptype(engine.get_binding_dtype(3)))\n",
    "    outputH1 = np.empty(context.get_binding_shape(4), dtype=trt.nptype(engine.get_binding_dtype(4)))\n",
    "    \n",
    "#     print(\"Reshaped\")\n",
    "\n",
    "    # initialize input and output data\n",
    "    _, inputD0 = cudart.cudaMallocAsync(inputH0.nbytes, stream)\n",
    "    _, inputD1 = cudart.cudaMallocAsync(inputH1.nbytes, stream)\n",
    "    _, inputD2 = cudart.cudaMallocAsync(inputH2.nbytes, stream)\n",
    "    _, outputD0 = cudart.cudaMallocAsync(outputH0.nbytes, stream)\n",
    "    _, outputD1 = cudart.cudaMallocAsync(outputH1.nbytes, stream)\n",
    "\n",
    "\n",
    "    # move input to device\n",
    "    cudart.cudaMemcpyAsync(inputD0, inputH0.ctypes.data, inputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n",
    "    cudart.cudaMemcpyAsync(inputD1, inputH1.ctypes.data, inputH1.nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n",
    "    cudart.cudaMemcpyAsync(inputD2, inputH2.ctypes.data, inputH2.nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n",
    "\n",
    "    # execute\n",
    "#     print(\"execute\")\n",
    "    context.execute_async_v2([int(inputD0), int(inputD1), int(inputD2), int(outputD0), int(outputD1)], stream)\n",
    "\n",
    "    # move output back to host\n",
    "    cudart.cudaMemcpyAsync(outputH0.ctypes.data, outputD0, outputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost, stream)\n",
    "    cudart.cudaMemcpyAsync(outputH1.ctypes.data, outputD1, outputH1.nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost, stream)\n",
    "\n",
    "    # wait for everythidden_sizeg\n",
    "    cudart.cudaStreamSynchronize(stream)\n",
    "\n",
    "    cudart.cudaStreamDestroy(stream)\n",
    "    cudart.cudaFree(inputD0)\n",
    "    cudart.cudaFree(inputD1)\n",
    "    cudart.cudaFree(inputD2)\n",
    "    cudart.cudaFree(outputD0)\n",
    "    cudart.cudaFree(outputD1)\n",
    "\n",
    "    return outputH0, outputH1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20e6bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_state = query_states.detach().numpy()\n",
    "k_state = key_states.detach().numpy()\n",
    "seq_len_mask = np.ones((seq_len, config[\"head_dim\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "208bb61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 32, 45, 128), (4, 32, 45, 128), (45, 128))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_state.shape, k_state.shape, seq_len_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f81b7578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime\n",
      "Set input shape: query_states\n",
      "(4, 32, -1, 128)\n",
      "Set input shape: key_states\n",
      "(4, 32, -1, 128)\n",
      "Set input shape: seq_len_mask\n",
      "(-1, 128)\n",
      "Set input shape completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4952/4011738329.py:12: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  q_shape = context.get_binding_shape(0)\n",
      "/tmp/ipykernel_4952/4011738329.py:15: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(0, (batch_size, num_attention_heads, seq_len, dim))\n",
      "/tmp/ipykernel_4952/4011738329.py:18: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  k_shape = context.get_binding_shape(1)\n",
      "/tmp/ipykernel_4952/4011738329.py:21: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(1, (batch_size, num_attention_heads, seq_len, dim))\n",
      "/tmp/ipykernel_4952/4011738329.py:24: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  mask_shape = context.get_binding_shape(2)\n",
      "/tmp/ipykernel_4952/4011738329.py:27: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(2, (seq_len, dim))\n",
      "/tmp/ipykernel_4952/4011738329.py:41: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(3), dtype=trt.nptype(engine.get_binding_dtype(3)))\n",
      "/tmp/ipykernel_4952/4011738329.py:41: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(3), dtype=trt.nptype(engine.get_binding_dtype(3)))\n",
      "/tmp/ipykernel_4952/4011738329.py:42: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  outputH1 = np.empty(context.get_binding_shape(4), dtype=trt.nptype(engine.get_binding_dtype(4)))\n",
      "/tmp/ipykernel_4952/4011738329.py:42: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  outputH1 = np.empty(context.get_binding_shape(4), dtype=trt.nptype(engine.get_binding_dtype(4)))\n"
     ]
    }
   ],
   "source": [
    "trt_output = trt_inference(batch_size, config[\"num_heads\"], config[\"head_dim\"],\n",
    "                           trt_engineStr, \n",
    "                           q_state, k_state, seq_len_mask)\n",
    "\n",
    "trt_query_states, trt_key_states = trt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6994a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 32, 45, 128) (4, 32, 45, 128)\n"
     ]
    }
   ],
   "source": [
    "print(trt_query_states.shape, trt_key_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0592b1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.7268712 , -0.07753751, -0.7819331 , ..., -0.48927367,\n",
       "         -0.14633395, -0.12997538],\n",
       "        [-0.5389836 , -0.8500305 , -0.81065595, ..., -0.48922914,\n",
       "         -0.14614709, -0.12986952],\n",
       "        [ 0.14444299, -1.023942  , -0.4044796 , ..., -0.4891846 ,\n",
       "         -0.14596021, -0.12976368],\n",
       "        ...,\n",
       "        [ 0.4500357 ,  1.0007448 , -0.8072869 , ..., -0.4873935 ,\n",
       "         -0.1384836 , -0.125528  ],\n",
       "        [-0.25892752,  0.3992397 , -0.78606105, ..., -0.48734847,\n",
       "         -0.13829663, -0.12542208],\n",
       "        [-0.72983396, -0.48340797, -0.34312868, ..., -0.48730347,\n",
       "         -0.13810965, -0.12531614]],\n",
       "\n",
       "       [[-0.88734734, -1.1440415 , -0.9657183 , ...,  0.43205604,\n",
       "         -0.21212707, -0.6659065 ],\n",
       "        [-0.63178384, -0.10507695, -0.466529  , ...,  0.4318235 ,\n",
       "         -0.21199818, -0.66590583],\n",
       "        [ 0.20463876,  1.0078816 ,  0.28294283, ...,  0.4315909 ,\n",
       "         -0.21186927, -0.6659051 ],\n",
       "        ...,\n",
       "        [ 0.5208617 , -1.0851523 , -0.93463045, ...,  0.42228022,\n",
       "         -0.20671044, -0.66586936],\n",
       "        [-0.3419858 , -1.3965178 , -0.39218572, ...,  0.42204726,\n",
       "         -0.20658138, -0.6658683 ],\n",
       "        [-0.8904131 , -0.72447014,  0.36066124, ...,  0.42181426,\n",
       "         -0.20645232, -0.6658672 ]],\n",
       "\n",
       "       [[ 0.49589366, -0.22685781, -0.18152794, ...,  0.18824825,\n",
       "          0.2129427 ,  0.20758514],\n",
       "        [ 0.71567   , -0.00681528, -0.36434448, ...,  0.18837273,\n",
       "          0.21295384,  0.20758325],\n",
       "        [ 0.27746263,  0.21802647, -0.3516982 , ...,  0.18849722,\n",
       "          0.21296497,  0.20758137],\n",
       "        ...,\n",
       "        [-0.6860212 , -0.23304985, -0.20797199, ...,  0.19347279,\n",
       "          0.21340707,  0.20750315],\n",
       "        [-0.167301  , -0.28513741, -0.37311992, ...,  0.19359708,\n",
       "          0.21341805,  0.20750114],\n",
       "        [ 0.50523496, -0.13643417, -0.33809698, ...,  0.19372137,\n",
       "          0.21342902,  0.20749913]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.06369157, -1.0731549 , -0.05010441, ..., -0.75592786,\n",
       "         -0.09936161, -0.2663857 ],\n",
       "        [-0.23954134, -1.0610657 , -0.48762652, ..., -0.7559574 ,\n",
       "         -0.0992893 , -0.2663882 ],\n",
       "        [-0.32254103, -0.3017864 , -0.6635477 , ..., -0.755987  ,\n",
       "         -0.09921698, -0.2663907 ],\n",
       "        ...,\n",
       "        [ 0.2729122 ,  0.20879486, -0.10257789, ..., -0.7571544 ,\n",
       "         -0.09632236, -0.2664878 ],\n",
       "        [ 0.30615368, -0.7460265 , -0.52187866, ..., -0.75718325,\n",
       "         -0.09624997, -0.26649016],\n",
       "        [ 0.05791888, -1.1755064 , -0.66120344, ..., -0.75721204,\n",
       "         -0.09617759, -0.26649252]],\n",
       "\n",
       "       [[-0.19412035, -0.46159863, -0.7176889 , ...,  0.00674346,\n",
       "          0.15227427, -0.87229043],\n",
       "        [-0.5795386 , -0.6413655 , -0.89364946, ...,  0.00674682,\n",
       "          0.1522382 , -0.87222046],\n",
       "        [-0.43213168, -0.3694903 , -0.59018666, ...,  0.00675018,\n",
       "          0.15220213, -0.8721505 ],\n",
       "        ...,\n",
       "        [ 0.5946343 ,  0.32555062, -0.75841916, ...,  0.00688404,\n",
       "          0.15075691, -0.86934197],\n",
       "        [ 0.36142668, -0.2125115 , -0.8833774 , ...,  0.00688739,\n",
       "          0.15072073, -0.86927146],\n",
       "        [-0.20407495, -0.6009268 , -0.53442144, ...,  0.00689075,\n",
       "          0.15068455, -0.869201  ]],\n",
       "\n",
       "       [[ 0.21559776,  0.28690228,  1.1821718 , ..., -0.6797007 ,\n",
       "         -0.3024037 ,  0.05354761],\n",
       "        [ 0.4714539 , -0.05724592,  0.921953  , ..., -0.67983437,\n",
       "         -0.3024136 ,  0.05348087],\n",
       "        [ 0.2938575 , -0.3610822 ,  0.16712664, ..., -0.67996806,\n",
       "         -0.30242348,  0.05341413],\n",
       "        ...,\n",
       "        [-0.47286108,  0.37867913,  1.1850652 , ..., -0.68530244,\n",
       "         -0.30281514,  0.05074399],\n",
       "        [-0.23119421,  0.39920068,  0.85979956, ..., -0.6854355 ,\n",
       "         -0.30282483,  0.05067722],\n",
       "        [ 0.22303154,  0.13860911,  0.07326708, ..., -0.68556845,\n",
       "         -0.30283448,  0.05061045]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_query_states[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459edd8b",
   "metadata": {},
   "source": [
    "## Is the result valid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2a2f5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output query state of Pytorch:torch.Size([4, 32, 45, 128])\n",
      "output query state of TensorRT:(4, 32, 45, 128)\n"
     ]
    }
   ],
   "source": [
    "print(\"output query state of Pytorch:\" + str(output_query_states.shape) )\n",
    "print(\"output query state of TensorRT:\" + str(trt_query_states.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "770ea6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(output_query_states.clone().detach().cpu().numpy(), trt_query_states, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af491c21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
