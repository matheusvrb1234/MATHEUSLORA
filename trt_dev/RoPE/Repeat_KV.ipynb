{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8abee90",
   "metadata": {},
   "source": [
    "# repeat_KV with TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afdaa8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cuda import cudart\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import tensorrt as trt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d806fc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0a0+4136153\n",
      "TensorRT version: 8.6.1\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version: \" + torch.__version__)\n",
    "print(\"TensorRT version: \" + trt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45641136",
   "metadata": {},
   "source": [
    "## 0. Generate input and data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6be09f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict()\n",
    "\n",
    "batch_size, seq_len, hidden_size = 4, 45, 4096\n",
    "intermediate_size = 11008\n",
    "num_attention_heads = 32\n",
    "num_key_value_heads = 32\n",
    "max_position_embeddings = 2048\n",
    "rope_theta = 10000.0\n",
    "\n",
    "config[\"hidden_size\"] = hidden_size\n",
    "config[\"num_heads\"] = num_attention_heads\n",
    "config[\"head_dim\"] = config[\"hidden_size\"] // config[\"num_heads\"]\n",
    "config[\"num_key_value_heads\"] = num_key_value_heads\n",
    "config[\"num_key_value_groups\"] = config[\"num_heads\"] // config[\"num_key_value_heads\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c7a5274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 45, 4096])\n",
      "Input query_states: before reshape torch.Size([4, 45, 4096])\n",
      "tensor([[-0.2101, -0.5661,  0.1543,  ..., -0.9110,  0.0716,  0.8272],\n",
      "        [-0.2101, -0.5661,  0.1543,  ..., -0.9110,  0.0716,  0.8272],\n",
      "        [-0.2101, -0.5661,  0.1543,  ..., -0.9110,  0.0716,  0.8272],\n",
      "        ...,\n",
      "        [-0.2101, -0.5661,  0.1543,  ..., -0.9110,  0.0716,  0.8272],\n",
      "        [-0.2101, -0.5661,  0.1543,  ..., -0.9110,  0.0716,  0.8272],\n",
      "        [-0.2101, -0.5661,  0.1543,  ..., -0.9110,  0.0716,  0.8272]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Input query_states: after reshape torch.Size([4, 32, 45, 128])\n",
      "tensor([[[-0.2101, -0.5661,  0.1543,  ...,  0.5787, -0.5385, -0.3816],\n",
      "         [-0.2101, -0.5661,  0.1543,  ...,  0.5787, -0.5385, -0.3816],\n",
      "         [-0.2101, -0.5661,  0.1543,  ...,  0.5787, -0.5385, -0.3816],\n",
      "         ...,\n",
      "         [-0.2101, -0.5661,  0.1543,  ...,  0.5787, -0.5385, -0.3816],\n",
      "         [-0.2101, -0.5661,  0.1543,  ...,  0.5787, -0.5385, -0.3816],\n",
      "         [-0.2101, -0.5661,  0.1543,  ...,  0.5787, -0.5385, -0.3816]],\n",
      "\n",
      "        [[-0.1047,  0.9981, -0.6422,  ...,  1.0532, -1.7630, -0.1402],\n",
      "         [-0.1047,  0.9981, -0.6422,  ...,  1.0532, -1.7630, -0.1402],\n",
      "         [-0.1047,  0.9981, -0.6422,  ...,  1.0532, -1.7630, -0.1402],\n",
      "         ...,\n",
      "         [-0.1047,  0.9981, -0.6422,  ...,  1.0532, -1.7630, -0.1402],\n",
      "         [-0.1047,  0.9981, -0.6422,  ...,  1.0532, -1.7630, -0.1402],\n",
      "         [-0.1047,  0.9981, -0.6422,  ...,  1.0532, -1.7630, -0.1402]],\n",
      "\n",
      "        [[ 0.4727,  0.5456, -0.3163,  ...,  1.0561,  0.4118,  0.3747],\n",
      "         [ 0.4727,  0.5456, -0.3163,  ...,  1.0561,  0.4118,  0.3747],\n",
      "         [ 0.4727,  0.5456, -0.3163,  ...,  1.0561,  0.4118,  0.3747],\n",
      "         ...,\n",
      "         [ 0.4727,  0.5456, -0.3163,  ...,  1.0561,  0.4118,  0.3747],\n",
      "         [ 0.4727,  0.5456, -0.3163,  ...,  1.0561,  0.4118,  0.3747],\n",
      "         [ 0.4727,  0.5456, -0.3163,  ...,  1.0561,  0.4118,  0.3747]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0057, -0.0321,  0.2648,  ...,  0.5674, -0.8909, -0.7276],\n",
      "         [ 0.0057, -0.0321,  0.2648,  ...,  0.5674, -0.8909, -0.7276],\n",
      "         [ 0.0057, -0.0321,  0.2648,  ...,  0.5674, -0.8909, -0.7276],\n",
      "         ...,\n",
      "         [ 0.0057, -0.0321,  0.2648,  ...,  0.5674, -0.8909, -0.7276],\n",
      "         [ 0.0057, -0.0321,  0.2648,  ...,  0.5674, -0.8909, -0.7276],\n",
      "         [ 0.0057, -0.0321,  0.2648,  ...,  0.5674, -0.8909, -0.7276]],\n",
      "\n",
      "        [[ 0.7257,  0.7129,  0.6500,  ..., -0.1436,  0.5869, -0.3623],\n",
      "         [ 0.7257,  0.7129,  0.6500,  ..., -0.1436,  0.5869, -0.3623],\n",
      "         [ 0.7257,  0.7129,  0.6500,  ..., -0.1436,  0.5869, -0.3623],\n",
      "         ...,\n",
      "         [ 0.7257,  0.7129,  0.6500,  ..., -0.1436,  0.5869, -0.3623],\n",
      "         [ 0.7257,  0.7129,  0.6500,  ..., -0.1436,  0.5869, -0.3623],\n",
      "         [ 0.7257,  0.7129,  0.6500,  ..., -0.1436,  0.5869, -0.3623]],\n",
      "\n",
      "        [[-1.1822, -0.9334, -0.6748,  ..., -0.9110,  0.0716,  0.8272],\n",
      "         [-1.1822, -0.9334, -0.6748,  ..., -0.9110,  0.0716,  0.8272],\n",
      "         [-1.1822, -0.9334, -0.6748,  ..., -0.9110,  0.0716,  0.8272],\n",
      "         ...,\n",
      "         [-1.1822, -0.9334, -0.6748,  ..., -0.9110,  0.0716,  0.8272],\n",
      "         [-1.1822, -0.9334, -0.6748,  ..., -0.9110,  0.0716,  0.8272],\n",
      "         [-1.1822, -0.9334, -0.6748,  ..., -0.9110,  0.0716,  0.8272]]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data = torch.ones(batch_size, seq_len, hidden_size)\n",
    "print(data.shape)\n",
    "\n",
    "## Prepare Pytorch Testing Parameter\n",
    "q_proj = nn.Linear(config[\"hidden_size\"], config[\"num_heads\"] * config[\"hidden_size\"] // config[\"num_heads\"], bias=False)\n",
    "k_proj = nn.Linear(config[\"hidden_size\"], config[\"num_key_value_heads\"] * config[\"head_dim\"], bias=False)\n",
    "v_proj = nn.Linear(config[\"hidden_size\"], config[\"num_key_value_heads\"] * config[\"head_dim\"], bias=False)\n",
    "\n",
    "query_states = q_proj(data)\n",
    "key_states = k_proj(data)\n",
    "value_states = v_proj(data)\n",
    "print(\"Input query_states: before reshape \" +str(query_states.shape))\n",
    "print(query_states[0])\n",
    "bsz, q_len, _ = data.size()\n",
    "\n",
    "# reshape\n",
    "query_states = query_states.view(bsz, q_len, config[\"num_heads\"], config[\"head_dim\"]).transpose(1, 2)\n",
    "key_states = key_states.view(bsz, q_len, config[\"num_key_value_heads\"], config[\"head_dim\"]).transpose(1, 2)\n",
    "value_states = value_states.view(bsz, q_len, config[\"num_key_value_heads\"], config[\"head_dim\"]).transpose(1, 2)\n",
    "print(\"Input query_states: after reshape \" + str(query_states.shape))\n",
    "print(query_states[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6988e5",
   "metadata": {},
   "source": [
    "## 1. Repeat_kv with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48770f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #####################################################\n",
    "# # in hugging face, they do have kv cache, however, they don't have other attention optimization\n",
    "# # this could be done directly in tensorRT by using dynamic shape\n",
    "# kv_seq_len = key_states.shape[-2]\n",
    "# if past_key_value is not None:\n",
    "#     kv_seq_len += past_key_value[0].shape[-2]\n",
    "\n",
    "# query_states, key_states = self.rotary_emb(query_states, key_states, value_states, position_ids, seq_len=q_len)\n",
    "\n",
    "# if past_key_value is not None:\n",
    "#     # reuse k, v, self_attention\n",
    "#     key_states = torch.cat([past_key_value[0], key_states], dim=2)\n",
    "#     value_states = torch.cat([past_key_value[1], value_states], dim=2)\n",
    "\n",
    "# past_key_value = (key_states, value_states) if use_cache else None\n",
    "\n",
    "# print(self.num_key_value_groups)\n",
    "# # repeat k/v heads if n_kv_heads < n_heads\n",
    "# key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
    "# value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
    "# #####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ad8508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    This is the equivalent of torch.repeat_interleave(x, dim=1, repeats=n_rep). The hidden states go from (batch,\n",
    "    num_key_value_heads, seqlen, head_dim) to (batch, num_attention_heads, seqlen, head_dim)\n",
    "    \n",
    "    repeat at the second dimension\n",
    "    \"\"\"\n",
    "    batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
    "    print(\"Input shape: \")\n",
    "    print(hidden_states.shape)\n",
    "    if n_rep == 1:\n",
    "        return hidden_states\n",
    "    hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
    "    print(\"Input shape after reshape: \")\n",
    "    print(hidden_states.shape)\n",
    "    return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c21c7560",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rep = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3126cb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: \n",
      "torch.Size([4, 32, 45, 128])\n",
      "Input shape after reshape: \n",
      "torch.Size([4, 32, 3, 45, 128])\n"
     ]
    }
   ],
   "source": [
    "key_states_repeat = repeat_kv(key_states, n_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5552f614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 96, 45, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_states_repeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64c72adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 2, 3, 1, 2, 3]])\n",
      "torch.Size([2, 9])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "print(x.shape)\n",
    "\n",
    "print(x.expand(2,3))\n",
    "print(x.expand(2,3).shape)\n",
    "\n",
    "print(x.repeat(2,3))\n",
    "print(x.repeat(2,3).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1124217d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 45, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d0cf627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 45, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_states.repeat(1, 2, 1, 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1022bd14",
   "metadata": {},
   "source": [
    "## 2. Repeat_kv with TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1972e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_create(batch_size, num_attention_heads, dim):\n",
    "    # Config TensorRT Logger, Builder, Network\n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    builder = trt.Builder(logger)\n",
    "\n",
    "    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "    config = builder.create_builder_config()\n",
    "\n",
    "    # inputs: hidden_state, n_rep with dynamic shape\n",
    "    hidden_states = network.add_input('hidden_states', trt.DataType.FLOAT, (batch_size, num_attention_heads, -1, dim))\n",
    "    repeat_states = network.add_input('repeat_states', trt.DataType.FLOAT, (batch_size, -1, -1, dim))\n",
    "    \n",
    "    # dynamic shape optimization\n",
    "    profile = builder.create_optimization_profile();\n",
    "    profile.set_shape(\"hidden_states\", \n",
    "                      (batch_size, num_attention_heads, 1, dim), \n",
    "                      (batch_size, num_attention_heads, 45, dim), \n",
    "                      (batch_size, num_attention_heads, 1024, dim))\n",
    "    profile.set_shape(\"repeat_states\", \n",
    "                      (batch_size, num_attention_heads, 1, dim), \n",
    "                      (batch_size, num_attention_heads*2, 45, dim), \n",
    "                      (batch_size, num_attention_heads*10, 1024, dim)) \n",
    "    \n",
    "    config.add_optimization_profile(profile)\n",
    "    \n",
    "    print(\"- 0) input: hidden_states, repeat_states shape :\")\n",
    "    print(hidden_states.shape, repeat_states.shape)\n",
    "\n",
    "    # 1. Get repeat_hidden_states shape with repeat_states\n",
    "    # Check detail how to do repeat like repeat in pytorch? #2408\n",
    "    # https://github.com/NVIDIA/TensorRT/issues/2408\n",
    "    print(\"- 1) Get repeat_hidden_states shape:\")\n",
    "    repeat_hidden_states_shape = network.add_shape(repeat_states)\n",
    "    print(repeat_hidden_states_shape.get_output(0).shape)\n",
    "    \n",
    "    print(\"- 2) repeat_hidden_states :\")\n",
    "    repeat_hidden_states = network.add_slice(hidden_states, start=(0, 0, 0, 0), shape=(1, 1, 1, 1), stride=(1, 1, 1, 1))\n",
    "    repeat_hidden_states.set_input(2, repeat_hidden_states_shape.get_output(0))\n",
    "    repeat_hidden_states.mode = trt.SliceMode.WRAP\n",
    "    \n",
    "    print(\"- 3) check repeat_hidden_states shape :\")\n",
    "    print(repeat_hidden_states.get_output(0).shape)\n",
    "    \n",
    "    network.mark_output(repeat_hidden_states.get_output(0))\n",
    "\n",
    "    engineString = builder.build_serialized_network(network, config)\n",
    "    \n",
    "    return engineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5630c944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 0) input: hidden_states, repeat_states shape :\n",
      "(4, 32, -1, 128) (4, -1, -1, 128)\n",
      "- 1) Get repeat_hidden_states shape:\n",
      "(4,)\n",
      "- 2) repeat_hidden_states :\n",
      "- 3) check repeat_hidden_states shape :\n",
      "(4, -1, -1, 128)\n"
     ]
    }
   ],
   "source": [
    "trt_engineStr = trt_create(batch_size = batch_size, \n",
    "                           num_attention_heads = config[\"num_heads\"],\n",
    "                           dim = config[\"head_dim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84234137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_inference(batch_size, num_attention_heads, dim, engineString, h_state, r_state): \n",
    "\n",
    "    print(\"Runtime\")\n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    engine = trt.Runtime(logger).deserialize_cuda_engine(engineString)\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    # dynamic shape configure\n",
    "    print(\"Set input shape: hidden_states\")\n",
    "    #context.active_optimization_profile = 0\n",
    "    \n",
    "    h_shape = context.get_binding_shape(0)\n",
    "    print(h_shape)\n",
    "    context.set_input_shape(\"hidden_states\", (batch_size, num_attention_heads, seq_len, dim))\n",
    "    context.set_binding_shape(0, (batch_size, num_attention_heads, seq_len, dim))\n",
    "\n",
    "    print(\"Set input shape: repeat_states\")\n",
    "    r_shape = context.get_binding_shape(1)\n",
    "    print(r_shape)\n",
    "    context.set_input_shape(\"repeat_states\", (batch_size, num_attention_heads, seq_len, dim))\n",
    "    context.set_binding_shape(1, (batch_size, num_attention_heads*n_rep, seq_len, dim))\n",
    " \n",
    "    print(\"Set input shape completed\")\n",
    "\n",
    "    h_state_data = np.array(h_state)\n",
    "    r_state_data = np.array(r_state)\n",
    "    \n",
    "    _, stream = cudart.cudaStreamCreate()\n",
    "\n",
    "    inputH0 = np.ascontiguousarray(h_state_data.reshape(-1))\n",
    "    inputH1 = np.ascontiguousarray(r_state_data.reshape(-1))\n",
    "    outputH0 = np.empty(context.get_binding_shape(2), dtype=trt.nptype(engine.get_binding_dtype(2)))\n",
    "\n",
    "    # initialize input and output data\n",
    "    _, inputD0 = cudart.cudaMallocAsync(inputH0.nbytes, stream)\n",
    "    _, inputD1 = cudart.cudaMallocAsync(inputH1.nbytes, stream)\n",
    "    _, outputD0 = cudart.cudaMallocAsync(outputH0.nbytes, stream)\n",
    "   \n",
    "    # move input to device\n",
    "    cudart.cudaMemcpyAsync(inputD0, inputH0.ctypes.data, inputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n",
    "    cudart.cudaMemcpyAsync(inputD1, inputH1.ctypes.data, inputH1.nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n",
    "    \n",
    "    # execute\n",
    "#     print(\"execute\")\n",
    "    context.execute_async_v2([int(inputD0), int(inputD1), int(outputD0)], stream)\n",
    "\n",
    "    # move output back to host\n",
    "    cudart.cudaMemcpyAsync(outputH0.ctypes.data, outputD0, outputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost, stream)\n",
    "    \n",
    "    # wait for everythidden_sizeg\n",
    "    cudart.cudaStreamSynchronize(stream)\n",
    "\n",
    "    cudart.cudaStreamDestroy(stream)\n",
    "    cudart.cudaFree(inputD0)\n",
    "    cudart.cudaFree(inputD1)\n",
    "    cudart.cudaFree(outputD0)\n",
    "\n",
    "    return outputH0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0baedf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_state = key_states.repeat(1, n_rep, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b81dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_state = key_states.detach().numpy()\n",
    "r_state = repeat_state.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44ead99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime\n",
      "Set input shape: hidden_states\n",
      "(4, 32, -1, 128)\n",
      "Set input shape: repeat_states\n",
      "(4, -1, -1, 128)\n",
      "Set input shape completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5055/2306405904.py:12: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  h_shape = context.get_binding_shape(0)\n",
      "/tmp/ipykernel_5055/2306405904.py:15: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(0, (batch_size, num_attention_heads, seq_len, dim))\n",
      "/tmp/ipykernel_5055/2306405904.py:18: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  r_shape = context.get_binding_shape(1)\n",
      "/tmp/ipykernel_5055/2306405904.py:21: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(1, (batch_size, num_attention_heads*n_rep, seq_len, dim))\n",
      "/tmp/ipykernel_5055/2306405904.py:32: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(2), dtype=trt.nptype(engine.get_binding_dtype(2)))\n",
      "/tmp/ipykernel_5055/2306405904.py:32: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(2), dtype=trt.nptype(engine.get_binding_dtype(2)))\n"
     ]
    }
   ],
   "source": [
    "trt_output = trt_inference(batch_size, config[\"num_heads\"], config[\"head_dim\"],\n",
    "                           trt_engineStr, \n",
    "                           h_state, r_state)\n",
    "\n",
    "trt_repeat_states = trt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dccc056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 96, 45, 128]), (4, 96, 45, 128))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_states_repeat.shape, trt_repeat_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b262ba2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087],\n",
       "         [-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087],\n",
       "         [-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087],\n",
       "         ...,\n",
       "         [-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087],\n",
       "         [-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087],\n",
       "         [-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087]],\n",
       "\n",
       "        [[-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087],\n",
       "         [-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087],\n",
       "         [-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087],\n",
       "         ...,\n",
       "         [-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087],\n",
       "         [-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087],\n",
       "         [-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087]],\n",
       "\n",
       "        [[-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087],\n",
       "         [-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087],\n",
       "         [-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087],\n",
       "         ...,\n",
       "         [-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087],\n",
       "         [-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087],\n",
       "         [-0.2323,  0.7661,  0.1553,  ..., -0.0610,  1.0893,  0.1087]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810],\n",
       "         [-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810],\n",
       "         [-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810],\n",
       "         ...,\n",
       "         [-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810],\n",
       "         [-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810],\n",
       "         [-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810]],\n",
       "\n",
       "        [[-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810],\n",
       "         [-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810],\n",
       "         [-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810],\n",
       "         ...,\n",
       "         [-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810],\n",
       "         [-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810],\n",
       "         [-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810]],\n",
       "\n",
       "        [[-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810],\n",
       "         [-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810],\n",
       "         [-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810],\n",
       "         ...,\n",
       "         [-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810],\n",
       "         [-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810],\n",
       "         [-0.0242, -0.8186, -0.5206,  ...,  0.5343,  1.0316,  0.3810]]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_states_repeat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "337badda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.23231319,  0.7661275 ,  0.15527761, ..., -0.06097494,\n",
       "          1.0892941 ,  0.1087038 ],\n",
       "        [-0.23231319,  0.7661275 ,  0.15527761, ..., -0.06097494,\n",
       "          1.0892941 ,  0.1087038 ],\n",
       "        [-0.23231319,  0.7661275 ,  0.15527761, ..., -0.06097494,\n",
       "          1.0892941 ,  0.1087038 ],\n",
       "        ...,\n",
       "        [-0.23231313,  0.7661277 ,  0.15527785, ..., -0.06097482,\n",
       "          1.0892944 ,  0.10870392],\n",
       "        [-0.23231313,  0.7661277 ,  0.15527785, ..., -0.06097482,\n",
       "          1.0892944 ,  0.10870392],\n",
       "        [-0.23231313,  0.7661277 ,  0.15527785, ..., -0.06097482,\n",
       "          1.0892944 ,  0.10870392]],\n",
       "\n",
       "       [[ 1.2015883 ,  0.4420061 , -0.05878636, ...,  0.0535775 ,\n",
       "         -0.6432709 , -0.21525244],\n",
       "        [ 1.2015883 ,  0.4420061 , -0.05878636, ...,  0.0535775 ,\n",
       "         -0.6432709 , -0.21525244],\n",
       "        [ 1.2015883 ,  0.4420061 , -0.05878636, ...,  0.0535775 ,\n",
       "         -0.6432709 , -0.21525244],\n",
       "        ...,\n",
       "        [ 1.2015884 ,  0.4420063 , -0.05878617, ...,  0.0535775 ,\n",
       "         -0.64327115, -0.21525252],\n",
       "        [ 1.2015884 ,  0.4420063 , -0.05878617, ...,  0.0535775 ,\n",
       "         -0.64327115, -0.21525252],\n",
       "        [ 1.2015884 ,  0.4420063 , -0.05878617, ...,  0.0535775 ,\n",
       "         -0.64327115, -0.21525252]],\n",
       "\n",
       "       [[ 0.33442372,  0.8366205 ,  0.9850102 , ...,  0.8880548 ,\n",
       "         -0.13445893, -0.14997722],\n",
       "        [ 0.33442372,  0.8366205 ,  0.9850102 , ...,  0.8880548 ,\n",
       "         -0.13445893, -0.14997722],\n",
       "        [ 0.33442372,  0.8366205 ,  0.9850102 , ...,  0.8880548 ,\n",
       "         -0.13445893, -0.14997722],\n",
       "        ...,\n",
       "        [ 0.3344236 ,  0.8366205 ,  0.98501015, ...,  0.8880546 ,\n",
       "         -0.13445924, -0.14997698],\n",
       "        [ 0.3344236 ,  0.8366205 ,  0.98501015, ...,  0.8880546 ,\n",
       "         -0.13445924, -0.14997698],\n",
       "        [ 0.3344236 ,  0.8366205 ,  0.98501015, ...,  0.8880546 ,\n",
       "         -0.13445924, -0.14997698]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.33570462, -0.39351737,  0.77882904, ..., -0.34991923,\n",
       "         -0.63382775,  0.35901192],\n",
       "        [ 0.33570462, -0.39351737,  0.77882904, ..., -0.34991923,\n",
       "         -0.63382775,  0.35901192],\n",
       "        [ 0.33570462, -0.39351737,  0.77882904, ..., -0.34991923,\n",
       "         -0.63382775,  0.35901192],\n",
       "        ...,\n",
       "        [ 0.3357047 , -0.39351723,  0.77882886, ..., -0.3499191 ,\n",
       "         -0.63382757,  0.35901174],\n",
       "        [ 0.3357047 , -0.39351723,  0.77882886, ..., -0.3499191 ,\n",
       "         -0.63382757,  0.35901174],\n",
       "        [ 0.3357047 , -0.39351723,  0.77882886, ..., -0.3499191 ,\n",
       "         -0.63382757,  0.35901174]],\n",
       "\n",
       "       [[ 0.03975169, -0.5715089 ,  0.28408134, ..., -0.14434241,\n",
       "          0.33940068, -0.56422645],\n",
       "        [ 0.03975169, -0.5715089 ,  0.28408134, ..., -0.14434241,\n",
       "          0.33940068, -0.56422645],\n",
       "        [ 0.03975169, -0.5715089 ,  0.28408134, ..., -0.14434241,\n",
       "          0.33940068, -0.56422645],\n",
       "        ...,\n",
       "        [ 0.03975147, -0.57150877,  0.28408146, ..., -0.14434232,\n",
       "          0.33940074, -0.56422615],\n",
       "        [ 0.03975147, -0.57150877,  0.28408146, ..., -0.14434232,\n",
       "          0.33940074, -0.56422615],\n",
       "        [ 0.03975147, -0.57150877,  0.28408146, ..., -0.14434232,\n",
       "          0.33940074, -0.56422615]],\n",
       "\n",
       "       [[-0.02416497, -0.81855655, -0.52056545, ...,  0.534313  ,\n",
       "          1.0316324 ,  0.38095266],\n",
       "        [-0.02416497, -0.81855655, -0.52056545, ...,  0.534313  ,\n",
       "          1.0316324 ,  0.38095266],\n",
       "        [-0.02416497, -0.81855655, -0.52056545, ...,  0.534313  ,\n",
       "          1.0316324 ,  0.38095266],\n",
       "        ...,\n",
       "        [-0.02416503, -0.8185564 , -0.5205653 , ...,  0.53431284,\n",
       "          1.0316323 ,  0.38095254],\n",
       "        [-0.02416503, -0.8185564 , -0.5205653 , ...,  0.53431284,\n",
       "          1.0316323 ,  0.38095254],\n",
       "        [-0.02416503, -0.8185564 , -0.5205653 , ...,  0.53431284,\n",
       "          1.0316323 ,  0.38095254]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_repeat_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa5e889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
