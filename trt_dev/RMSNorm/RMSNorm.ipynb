{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7171aa81",
   "metadata": {},
   "source": [
    "# RMSNorm with TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22859cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cuda import cudart\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import tensorrt as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9493668b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0a0+4136153\n",
      "TensorRT version: 8.6.1\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version: \" + torch.__version__)\n",
    "print(\"TensorRT version: \" + trt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de071e05",
   "metadata": {},
   "source": [
    "## Generate input and data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b51911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputH0 : (4, 45, 4096)\n",
      "[[[0.00000e+00 1.00000e+00 2.00000e+00 ... 4.09300e+03 4.09400e+03\n",
      "   4.09500e+03]\n",
      "  [4.09600e+03 4.09700e+03 4.09800e+03 ... 8.18900e+03 8.19000e+03\n",
      "   8.19100e+03]\n",
      "  [8.19200e+03 8.19300e+03 8.19400e+03 ... 1.22850e+04 1.22860e+04\n",
      "   1.22870e+04]\n",
      "  ...\n",
      "  [1.72032e+05 1.72033e+05 1.72034e+05 ... 1.76125e+05 1.76126e+05\n",
      "   1.76127e+05]\n",
      "  [1.76128e+05 1.76129e+05 1.76130e+05 ... 1.80221e+05 1.80222e+05\n",
      "   1.80223e+05]\n",
      "  [1.80224e+05 1.80225e+05 1.80226e+05 ... 1.84317e+05 1.84318e+05\n",
      "   1.84319e+05]]\n",
      "\n",
      " [[1.84320e+05 1.84321e+05 1.84322e+05 ... 1.88413e+05 1.88414e+05\n",
      "   1.88415e+05]\n",
      "  [1.88416e+05 1.88417e+05 1.88418e+05 ... 1.92509e+05 1.92510e+05\n",
      "   1.92511e+05]\n",
      "  [1.92512e+05 1.92513e+05 1.92514e+05 ... 1.96605e+05 1.96606e+05\n",
      "   1.96607e+05]\n",
      "  ...\n",
      "  [3.56352e+05 3.56353e+05 3.56354e+05 ... 3.60445e+05 3.60446e+05\n",
      "   3.60447e+05]\n",
      "  [3.60448e+05 3.60449e+05 3.60450e+05 ... 3.64541e+05 3.64542e+05\n",
      "   3.64543e+05]\n",
      "  [3.64544e+05 3.64545e+05 3.64546e+05 ... 3.68637e+05 3.68638e+05\n",
      "   3.68639e+05]]\n",
      "\n",
      " [[3.68640e+05 3.68641e+05 3.68642e+05 ... 3.72733e+05 3.72734e+05\n",
      "   3.72735e+05]\n",
      "  [3.72736e+05 3.72737e+05 3.72738e+05 ... 3.76829e+05 3.76830e+05\n",
      "   3.76831e+05]\n",
      "  [3.76832e+05 3.76833e+05 3.76834e+05 ... 3.80925e+05 3.80926e+05\n",
      "   3.80927e+05]\n",
      "  ...\n",
      "  [5.40672e+05 5.40673e+05 5.40674e+05 ... 5.44765e+05 5.44766e+05\n",
      "   5.44767e+05]\n",
      "  [5.44768e+05 5.44769e+05 5.44770e+05 ... 5.48861e+05 5.48862e+05\n",
      "   5.48863e+05]\n",
      "  [5.48864e+05 5.48865e+05 5.48866e+05 ... 5.52957e+05 5.52958e+05\n",
      "   5.52959e+05]]\n",
      "\n",
      " [[5.52960e+05 5.52961e+05 5.52962e+05 ... 5.57053e+05 5.57054e+05\n",
      "   5.57055e+05]\n",
      "  [5.57056e+05 5.57057e+05 5.57058e+05 ... 5.61149e+05 5.61150e+05\n",
      "   5.61151e+05]\n",
      "  [5.61152e+05 5.61153e+05 5.61154e+05 ... 5.65245e+05 5.65246e+05\n",
      "   5.65247e+05]\n",
      "  ...\n",
      "  [7.24992e+05 7.24993e+05 7.24994e+05 ... 7.29085e+05 7.29086e+05\n",
      "   7.29087e+05]\n",
      "  [7.29088e+05 7.29089e+05 7.29090e+05 ... 7.33181e+05 7.33182e+05\n",
      "   7.33183e+05]\n",
      "  [7.33184e+05 7.33185e+05 7.33186e+05 ... 7.37277e+05 7.37278e+05\n",
      "   7.37279e+05]]]\n"
     ]
    }
   ],
   "source": [
    "# Input tensor shape NCHW\n",
    "nIn, hIn, wIn = 4, 45, 4096\n",
    "\n",
    "# Output tensor shape C\n",
    "cOut = 2\n",
    "\n",
    "# Input tensor\n",
    "data = np.arange(nIn * hIn * wIn, dtype=np.float32).reshape(nIn, hIn, wIn)\n",
    "\n",
    "# fully connected weight\n",
    "#weight = np.ones(cOut * hIn * wIn, dtype=np.float32).reshape(cOut, hIn * wIn)\n",
    "\n",
    "# fully connected bias\n",
    "#bias = np.zeros(cOut, dtype=np.float32)\n",
    "\n",
    "print(\"inputH0 :\", data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f897a",
   "metadata": {},
   "source": [
    "## 1. RMSNorm by PyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "425f6b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        # The gamma parameter\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "        self.eps = eps\n",
    "\n",
    "    def _norm(self, x: torch.Tensor):\n",
    "        # (B, Seq_Len, Dim) * (B, Seq_Len, 1) = (B, Seq_Len, Dim)\n",
    "        # rsqrt: 1 / sqrt(x)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # (Dim) * (B, Seq_Len, Dim) = (B, Seq_Len, Dim)\n",
    "        return self.weight * self._norm(x.float()).type_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "317d820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_torch(nIn, hIn, wIn, cOut, raw_data):\n",
    "    data = torch.tensor(raw_data).reshape(-1)\n",
    "    \n",
    "    model = RMSNorm(1)\n",
    "\n",
    "    output = model(data)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5460c242",
   "metadata": {},
   "source": [
    "## PyTorch Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ba8ee72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSNorm_output_torch : torch.Size([737280])\n",
      "tensor([0.0000e+00, 2.3492e-06, 4.6985e-06,  ..., 1.7320e+00, 1.7320e+00,\n",
      "        1.7321e+00], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch_output = test_torch(nIn, hIn, wIn, cOut, data)\n",
    "print(\"RMSNorm_output_torch :\", torch_output.shape)\n",
    "print(torch_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8eeef",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34227c48",
   "metadata": {},
   "source": [
    "## 2. RMSNorm with TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd7d648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_create(nIn, hIn, wIn, cOut):\n",
    "    # Config TensorRT Logger, Builder, Network\n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    builder = trt.Builder(logger)\n",
    "\n",
    "    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "    config = builder.create_builder_config()\n",
    "\n",
    "    # input\n",
    "    inputT0 = network.add_input('inputT0', trt.DataType.FLOAT, [-1])\n",
    "    avg_factor = np.array([nIn * hIn * wIn]).astype('float32')\n",
    "    epsilon_weight = np.array([1e-06]).astype('float32')\n",
    "    avg_tensor = network.add_constant(shape=list(avg_factor.shape), weights=trt.Weights(avg_factor))\n",
    "    epsilon = network.add_constant(shape=list(epsilon_weight.shape), weights=trt.Weights(epsilon_weight))\n",
    "\n",
    "    # dynamic shape optimization\n",
    "    profile = builder.create_optimization_profile();\n",
    "    profile.set_shape(\"inputT0\", [1], [hIn*wIn], [nIn*hIn*wIn]) \n",
    "    config.add_optimization_profile(profile)\n",
    "\n",
    "    # RMSNorm Layer: 1) Square: X^2 -> 2) Sum: sum of all x^2 -> 3) Mean: 1/N \n",
    "    # -> 4) Add epsilon -> 5) Root: sqrt(X) -> 6) Division: 1/X\n",
    "    print(\"inputT0.shape :\")\n",
    "    print(inputT0.shape)\n",
    "    # 1) Square: X^2\n",
    "    RMSNorm_Square_layer = network.add_elementwise(inputT0, inputT0, op=trt.ElementWiseOperation.PROD)\n",
    "    print(\"RMSNorm_Square_layer.get_output(0).shape :\")\n",
    "    print(RMSNorm_Square_layer.get_output(0).shape)\n",
    "    # 2) Sum: sum of all X^2\n",
    "    RMSNorm_Sum_layer = network.add_reduce(RMSNorm_Square_layer.get_output(0), op=trt.ReduceOperation.SUM, axes=1, keep_dims=True)\n",
    "    print(\"RMSNorm_Sum_layer.get_output(0).shape :\")\n",
    "    print(RMSNorm_Sum_layer.get_output(0).shape)\n",
    "    # 3) Mean: 1/N\n",
    "    RMSNorm_Mean_layer = network.add_elementwise(RMSNorm_Sum_layer.get_output(0),\n",
    "                                                 avg_tensor.get_output(0),\n",
    "                                                 op=trt.ElementWiseOperation.DIV)\n",
    "    print(\"RMSNorm_Mean_layer.get_output(0).shape :\")\n",
    "    print(RMSNorm_Mean_layer.get_output(0).shape)\n",
    "    # 4) Add epsilon\n",
    "    RMSNorm_Mean_with_epsilon_layer = network.add_elementwise(RMSNorm_Mean_layer.get_output(0),\n",
    "                                                              epsilon.get_output(0), \n",
    "                                                              op=trt.ElementWiseOperation.SUM)\n",
    "    print(\"RMSNorm_Mean_with_epsilon_layer.get_output(0).shape :\")\n",
    "    print(RMSNorm_Mean_with_epsilon_layer.get_output(0).shape)\n",
    "    # 5) Root: sqrt(X)\n",
    "    RMSNorm_Sqrt_layer = network.add_unary(RMSNorm_Mean_with_epsilon_layer.get_output(0), op=trt.UnaryOperation.SQRT)\n",
    "    print(\"RMSNorm_Sqrt_layer.get_output(0).shape :\")\n",
    "    print(RMSNorm_Sqrt_layer.get_output(0).shape)\n",
    "    # 6) Division: 1/X\n",
    "    RMSNorm_Div_layer = network.add_elementwise(inputT0, RMSNorm_Sqrt_layer.get_output(0), op=trt.ElementWiseOperation.DIV)\n",
    "    print(\"RMSNorm_Div_layer.get_output(0).shape :\")\n",
    "    print(RMSNorm_Div_layer.get_output(0).shape)\n",
    "    # output\n",
    "    network.mark_output(RMSNorm_Div_layer.get_output(0))\n",
    "\n",
    "    engineString = builder.build_serialized_network(network, config)\n",
    "    \n",
    "    return engineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e1fc598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputT0.shape :\n",
      "(-1,)\n",
      "RMSNorm_Square_layer.get_output(0).shape :\n",
      "(-1,)\n",
      "RMSNorm_Sum_layer.get_output(0).shape :\n",
      "(1,)\n",
      "RMSNorm_Mean_layer.get_output(0).shape :\n",
      "(1,)\n",
      "RMSNorm_Mean_with_epsilon_layer.get_output(0).shape :\n",
      "(1,)\n",
      "RMSNorm_Sqrt_layer.get_output(0).shape :\n",
      "(1,)\n",
      "RMSNorm_Div_layer.get_output(0).shape :\n",
      "(-1,)\n"
     ]
    }
   ],
   "source": [
    "trt_engineStr = trt_create(nIn, hIn, wIn, cOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fddc76c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_inference(nIn, hIn, wIn, cOut, engineString, raw_data):\n",
    "    #print(engineString)\n",
    "    #print(\"Runtime\")\n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    engine = trt.Runtime(logger).deserialize_cuda_engine(engineString)\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    # dynamic shape configure\n",
    "    #print(\"Set input shape\")\n",
    "    context.set_input_shape(\"inputT0\", [nIn * hIn * wIn])\n",
    "    context.set_binding_shape(0, [nIn * hIn * wIn])\n",
    "    origin_inputshape = context.get_binding_shape(0)\n",
    "\n",
    "    #print(\"Set input shape completed\")\n",
    "\n",
    "    data = np.array(raw_data).reshape(-1)\n",
    "\n",
    "    _, stream = cudart.cudaStreamCreate()\n",
    "    #print(\"Reshaping\")\n",
    "\n",
    "    inputH0 = np.ascontiguousarray(data.reshape(-1))\n",
    "    outputH0 = np.empty(context.get_binding_shape(1), dtype=trt.nptype(engine.get_binding_dtype(1)))\n",
    "    #print(\"Reshaped\")\n",
    "\n",
    "    # initialize input and output data\n",
    "    _, inputD0 = cudart.cudaMallocAsync(inputH0.nbytes, stream)\n",
    "    _, outputD0 = cudart.cudaMallocAsync(outputH0.nbytes, stream)\n",
    "\n",
    "    # move input to device\n",
    "    cudart.cudaMemcpyAsync(inputD0, inputH0.ctypes.data, inputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n",
    "\n",
    "    # execute\n",
    "    #print(\"execute\")\n",
    "    context.execute_async_v2([int(inputD0), int(outputD0)], stream)\n",
    "\n",
    "    # move output back to host\n",
    "    cudart.cudaMemcpyAsync(outputH0.ctypes.data, outputD0, outputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost, stream)\n",
    "\n",
    "    # wait for everything\n",
    "    cudart.cudaStreamSynchronize(stream)\n",
    "\n",
    "    cudart.cudaStreamDestroy(stream)\n",
    "    cudart.cudaFree(inputD0)\n",
    "    cudart.cudaFree(outputD0)\n",
    "\n",
    "    return outputH0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b76b4a",
   "metadata": {},
   "source": [
    "## Testing TensorRT Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "587ee451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSNorm_output_trt - without reshape : (737280,)\n",
      "RMSNorm_output_trt : (737280,)\n",
      "[0.0000000e+00 2.3492469e-06 4.6984937e-06 ... 1.7320457e+00 1.7320480e+00\n",
      " 1.7320503e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2807/1043403431.py:11: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(0, [nIn * hIn * wIn])\n",
      "/tmp/ipykernel_2807/1043403431.py:12: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  origin_inputshape = context.get_binding_shape(0)\n",
      "/tmp/ipykernel_2807/1043403431.py:22: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(1), dtype=trt.nptype(engine.get_binding_dtype(1)))\n",
      "/tmp/ipykernel_2807/1043403431.py:22: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(1), dtype=trt.nptype(engine.get_binding_dtype(1)))\n"
     ]
    }
   ],
   "source": [
    "trt_output = trt_inference(nIn, hIn, wIn, cOut, trt_engineStr, data)\n",
    "print(\"RMSNorm_output_trt - without reshape :\", trt_output.shape)\n",
    "trt_output = trt_output.reshape(-1)\n",
    "print(\"RMSNorm_output_trt :\", trt_output.shape)\n",
    "print(trt_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0273706e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60cf46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
