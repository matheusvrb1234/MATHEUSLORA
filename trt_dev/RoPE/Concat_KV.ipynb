{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6695aea8",
   "metadata": {},
   "source": [
    "# repeat_KV with TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21c68db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cuda import cudart\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import tensorrt as trt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25929036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0a0+4136153\n",
      "TensorRT version: 8.6.1\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version: \" + torch.__version__)\n",
    "print(\"TensorRT version: \" + trt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b831c38",
   "metadata": {},
   "source": [
    "## 0. Generate input and data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fedcf2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict()\n",
    "\n",
    "batch_size, seq_len, hidden_size = 4, 45, 4096\n",
    "intermediate_size = 11008\n",
    "num_attention_heads = 32\n",
    "num_key_value_heads = 32\n",
    "max_position_embeddings = 2048\n",
    "rope_theta = 10000.0\n",
    "\n",
    "config[\"hidden_size\"] = hidden_size\n",
    "config[\"num_heads\"] = num_attention_heads\n",
    "config[\"head_dim\"] = config[\"hidden_size\"] // config[\"num_heads\"]\n",
    "config[\"num_key_value_heads\"] = num_key_value_heads\n",
    "config[\"num_key_value_groups\"] = config[\"num_heads\"] // config[\"num_key_value_heads\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e16efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 45, 4096])\n",
      "Input query_states: before reshape torch.Size([4, 45, 4096])\n",
      "tensor([[ 0.6771,  0.0336,  0.7661,  ..., -0.1484,  0.5155, -0.7554],\n",
      "        [ 0.6771,  0.0336,  0.7661,  ..., -0.1484,  0.5155, -0.7554],\n",
      "        [ 0.6771,  0.0336,  0.7661,  ..., -0.1484,  0.5155, -0.7554],\n",
      "        ...,\n",
      "        [ 0.6771,  0.0336,  0.7661,  ..., -0.1484,  0.5155, -0.7554],\n",
      "        [ 0.6771,  0.0336,  0.7661,  ..., -0.1484,  0.5155, -0.7554],\n",
      "        [ 0.6771,  0.0336,  0.7661,  ..., -0.1484,  0.5155, -0.7554]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Input query_states: after reshape torch.Size([4, 32, 45, 128])\n",
      "tensor([[[ 0.6771,  0.0336,  0.7661,  ...,  0.7346, -0.6431, -0.2101],\n",
      "         [ 0.6771,  0.0336,  0.7661,  ...,  0.7346, -0.6431, -0.2101],\n",
      "         [ 0.6771,  0.0336,  0.7661,  ...,  0.7346, -0.6431, -0.2101],\n",
      "         ...,\n",
      "         [ 0.6771,  0.0336,  0.7661,  ...,  0.7346, -0.6431, -0.2101],\n",
      "         [ 0.6771,  0.0336,  0.7661,  ...,  0.7346, -0.6431, -0.2101],\n",
      "         [ 0.6771,  0.0336,  0.7661,  ...,  0.7346, -0.6431, -0.2101]],\n",
      "\n",
      "        [[ 0.3365,  0.2218, -0.5468,  ..., -0.0501,  0.1085, -1.2698],\n",
      "         [ 0.3365,  0.2218, -0.5468,  ..., -0.0501,  0.1085, -1.2698],\n",
      "         [ 0.3365,  0.2218, -0.5468,  ..., -0.0501,  0.1085, -1.2698],\n",
      "         ...,\n",
      "         [ 0.3365,  0.2218, -0.5468,  ..., -0.0501,  0.1085, -1.2698],\n",
      "         [ 0.3365,  0.2218, -0.5468,  ..., -0.0501,  0.1085, -1.2698],\n",
      "         [ 0.3365,  0.2218, -0.5468,  ..., -0.0501,  0.1085, -1.2698]],\n",
      "\n",
      "        [[-0.3729, -0.2354, -0.1012,  ..., -0.1191,  0.4190, -0.3595],\n",
      "         [-0.3729, -0.2354, -0.1012,  ..., -0.1191,  0.4190, -0.3595],\n",
      "         [-0.3729, -0.2354, -0.1012,  ..., -0.1191,  0.4190, -0.3595],\n",
      "         ...,\n",
      "         [-0.3729, -0.2354, -0.1012,  ..., -0.1191,  0.4190, -0.3595],\n",
      "         [-0.3729, -0.2354, -0.1012,  ..., -0.1191,  0.4190, -0.3595],\n",
      "         [-0.3729, -0.2354, -0.1012,  ..., -0.1191,  0.4190, -0.3595]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5543, -0.9670,  0.9143,  ...,  0.7543,  0.7016, -0.5306],\n",
      "         [ 0.5543, -0.9670,  0.9143,  ...,  0.7543,  0.7016, -0.5306],\n",
      "         [ 0.5543, -0.9670,  0.9143,  ...,  0.7543,  0.7016, -0.5306],\n",
      "         ...,\n",
      "         [ 0.5543, -0.9670,  0.9143,  ...,  0.7543,  0.7016, -0.5306],\n",
      "         [ 0.5543, -0.9670,  0.9143,  ...,  0.7543,  0.7016, -0.5306],\n",
      "         [ 0.5543, -0.9670,  0.9143,  ...,  0.7543,  0.7016, -0.5306]],\n",
      "\n",
      "        [[ 0.4025,  0.0208,  0.4971,  ..., -0.6736,  0.2671,  0.0428],\n",
      "         [ 0.4025,  0.0208,  0.4971,  ..., -0.6736,  0.2671,  0.0428],\n",
      "         [ 0.4025,  0.0208,  0.4971,  ..., -0.6736,  0.2671,  0.0428],\n",
      "         ...,\n",
      "         [ 0.4025,  0.0208,  0.4971,  ..., -0.6736,  0.2671,  0.0428],\n",
      "         [ 0.4025,  0.0208,  0.4971,  ..., -0.6736,  0.2671,  0.0428],\n",
      "         [ 0.4025,  0.0208,  0.4971,  ..., -0.6736,  0.2671,  0.0428]],\n",
      "\n",
      "        [[ 0.2645, -0.4934,  0.6524,  ..., -0.1484,  0.5155, -0.7554],\n",
      "         [ 0.2645, -0.4934,  0.6524,  ..., -0.1484,  0.5155, -0.7554],\n",
      "         [ 0.2645, -0.4934,  0.6524,  ..., -0.1484,  0.5155, -0.7554],\n",
      "         ...,\n",
      "         [ 0.2645, -0.4934,  0.6524,  ..., -0.1484,  0.5155, -0.7554],\n",
      "         [ 0.2645, -0.4934,  0.6524,  ..., -0.1484,  0.5155, -0.7554],\n",
      "         [ 0.2645, -0.4934,  0.6524,  ..., -0.1484,  0.5155, -0.7554]]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data = torch.ones(batch_size, seq_len, hidden_size)\n",
    "print(data.shape)\n",
    "\n",
    "## Prepare Pytorch Testing Parameter\n",
    "q_proj = nn.Linear(config[\"hidden_size\"], config[\"num_heads\"] * config[\"hidden_size\"] // config[\"num_heads\"], bias=False)\n",
    "k_proj = nn.Linear(config[\"hidden_size\"], config[\"num_key_value_heads\"] * config[\"head_dim\"], bias=False)\n",
    "v_proj = nn.Linear(config[\"hidden_size\"], config[\"num_key_value_heads\"] * config[\"head_dim\"], bias=False)\n",
    "\n",
    "query_states = q_proj(data)\n",
    "key_states = k_proj(data)\n",
    "value_states = v_proj(data)\n",
    "print(\"Input query_states: before reshape \" +str(query_states.shape))\n",
    "print(query_states[0])\n",
    "bsz, q_len, _ = data.size()\n",
    "\n",
    "# reshape\n",
    "query_states = query_states.view(bsz, q_len, config[\"num_heads\"], config[\"head_dim\"]).transpose(1, 2)\n",
    "key_states = key_states.view(bsz, q_len, config[\"num_key_value_heads\"], config[\"head_dim\"]).transpose(1, 2)\n",
    "value_states = value_states.view(bsz, q_len, config[\"num_key_value_heads\"], config[\"head_dim\"]).transpose(1, 2)\n",
    "print(\"Input query_states: after reshape \" + str(query_states.shape))\n",
    "print(query_states[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8fb708",
   "metadata": {},
   "source": [
    "## 1. Repeat_kv with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efd2a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #####################################################\n",
    "# # in hugging face, they do have kv cache, however, they don't have other attention optimization\n",
    "# # this could be done directly in tensorRT by using dynamic shape\n",
    "# kv_seq_len = key_states.shape[-2]\n",
    "# if past_key_value is not None:\n",
    "#     kv_seq_len += past_key_value[0].shape[-2]\n",
    "\n",
    "# query_states, key_states = self.rotary_emb(query_states, key_states, value_states, position_ids, seq_len=q_len)\n",
    "\n",
    "# if past_key_value is not None:\n",
    "#     # reuse k, v, self_attention\n",
    "#     key_states = torch.cat([past_key_value[0], key_states], dim=2)\n",
    "#     value_states = torch.cat([past_key_value[1], value_states], dim=2)\n",
    "\n",
    "# past_key_value = (key_states, value_states) if use_cache else None\n",
    "\n",
    "# print(self.num_key_value_groups)\n",
    "# # repeat k/v heads if n_kv_heads < n_heads\n",
    "# key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
    "# value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
    "# #####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6acb590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_kv(hidden_states: torch.Tensor, hidden_states_2: torch.Tensor,) -> torch.Tensor:\n",
    "    print(\"Input shape : \")\n",
    "    print(hidden_states.shape)\n",
    "    new_states = torch.cat([hidden_states, hidden_states_2], dim=2)\n",
    "    print(\"Output shape : \")\n",
    "    print(new_states.shape)\n",
    "    return new_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60de4478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape : \n",
      "torch.Size([4, 32, 45, 128])\n",
      "Output shape : \n",
      "torch.Size([4, 32, 90, 128])\n"
     ]
    }
   ],
   "source": [
    "concat_key_states = concat_kv(key_states, key_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa94f924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 90, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_key_states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e5fd1c",
   "metadata": {},
   "source": [
    "## 2. Concat_kv with TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01bbb0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_create(batch_size, num_attention_heads, dim):\n",
    "    # Config TensorRT Logger, Builder, Network\n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    builder = trt.Builder(logger)\n",
    "\n",
    "    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "    config = builder.create_builder_config()\n",
    "\n",
    "    # inputs: hidden_state, n_rep with dynamic shape\n",
    "    hidden_states = network.add_input('hidden_states', trt.DataType.FLOAT, (batch_size, num_attention_heads, -1, dim))\n",
    "    hidden_states_2 = network.add_input('hidden_states_2', trt.DataType.FLOAT, (batch_size, num_attention_heads, -1, dim))\n",
    "    \n",
    "    # dynamic shape optimization\n",
    "    profile = builder.create_optimization_profile();\n",
    "    profile.set_shape(\"hidden_states\", \n",
    "                      (batch_size, num_attention_heads, 1, dim), \n",
    "                      (batch_size, num_attention_heads, 45, dim), \n",
    "                      (batch_size, num_attention_heads, 1024, dim))\n",
    "    profile.set_shape(\"hidden_states_2\", \n",
    "                      (batch_size, num_attention_heads, 1, dim), \n",
    "                      (batch_size, num_attention_heads, 45, dim), \n",
    "                      (batch_size, num_attention_heads, 1024, dim)) \n",
    "    \n",
    "    config.add_optimization_profile(profile)\n",
    "    \n",
    "    print(\"- 0) input: hidden_states, repeat_states shape :\")\n",
    "    print(hidden_states.shape, hidden_states_2.shape)\n",
    "\n",
    "    print(\"- 1) Get concat_states shape:\")\n",
    "    concat_states = network.add_concatenation([hidden_states, hidden_states_2])\n",
    "    concat_states.axis = 2\n",
    "    \n",
    "    print(concat_states.get_output(0).shape)\n",
    "  \n",
    "    network.mark_output(concat_states.get_output(0))\n",
    "\n",
    "    engineString = builder.build_serialized_network(network, config)\n",
    "    \n",
    "    return engineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f857617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 0) input: hidden_states, repeat_states shape :\n",
      "(4, 32, -1, 128) (4, 32, -1, 128)\n",
      "- 1) Get concat_states shape:\n",
      "(4, 32, -1, 128)\n"
     ]
    }
   ],
   "source": [
    "trt_engineStr = trt_create(batch_size = batch_size, \n",
    "                           num_attention_heads = config[\"num_heads\"],\n",
    "                           dim = config[\"head_dim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61cb849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_inference(batch_size, num_attention_heads, dim, engineString, h_state, h_state_2): \n",
    "\n",
    "    print(\"Runtime\")\n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    engine = trt.Runtime(logger).deserialize_cuda_engine(engineString)\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    # dynamic shape configure\n",
    "    print(\"Set input shape: hidden_states\")\n",
    "    #context.active_optimization_profile = 0\n",
    "    \n",
    "    h_shape = context.get_binding_shape(0)\n",
    "    print(h_shape)\n",
    "    context.set_input_shape(\"hidden_states\", (batch_size, num_attention_heads, seq_len, dim))\n",
    "    context.set_binding_shape(0, (batch_size, num_attention_heads, seq_len, dim))\n",
    "\n",
    "    print(\"Set input shape: repeat_states\")\n",
    "    h_shape_2 = context.get_binding_shape(1)\n",
    "    print(h_shape_2)\n",
    "    context.set_input_shape(\"hidden_states_2\", (batch_size, num_attention_heads, seq_len, dim))\n",
    "    context.set_binding_shape(1, (batch_size, num_attention_heads, seq_len, dim))\n",
    " \n",
    "    print(\"Set input shape completed\")\n",
    "\n",
    "    h_state_data = np.array(h_state)\n",
    "    h_state_2_data = np.array(h_state_2)\n",
    "    \n",
    "    _, stream = cudart.cudaStreamCreate()\n",
    "\n",
    "    inputH0 = np.ascontiguousarray(h_state_data.reshape(-1))\n",
    "    inputH1 = np.ascontiguousarray(h_state_2_data.reshape(-1))\n",
    "    outputH0 = np.empty(context.get_binding_shape(2), dtype=trt.nptype(engine.get_binding_dtype(2)))\n",
    "\n",
    "    # initialize input and output data\n",
    "    _, inputD0 = cudart.cudaMallocAsync(inputH0.nbytes, stream)\n",
    "    _, inputD1 = cudart.cudaMallocAsync(inputH1.nbytes, stream)\n",
    "    _, outputD0 = cudart.cudaMallocAsync(outputH0.nbytes, stream)\n",
    "   \n",
    "    # move input to device\n",
    "    cudart.cudaMemcpyAsync(inputD0, inputH0.ctypes.data, inputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n",
    "    cudart.cudaMemcpyAsync(inputD1, inputH1.ctypes.data, inputH1.nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n",
    "    \n",
    "    # execute\n",
    "#     print(\"execute\")\n",
    "    context.execute_async_v2([int(inputD0), int(inputD1), int(outputD0)], stream)\n",
    "\n",
    "    # move output back to host\n",
    "    cudart.cudaMemcpyAsync(outputH0.ctypes.data, outputD0, outputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost, stream)\n",
    "    \n",
    "    # wait for everythidden_sizeg\n",
    "    cudart.cudaStreamSynchronize(stream)\n",
    "\n",
    "    cudart.cudaStreamDestroy(stream)\n",
    "    cudart.cudaFree(inputD0)\n",
    "    cudart.cudaFree(inputD1)\n",
    "    cudart.cudaFree(outputD0)\n",
    "\n",
    "    return outputH0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "654f09aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_state = key_states.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a49c53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime\n",
      "Set input shape: hidden_states\n",
      "(4, 32, -1, 128)\n",
      "Set input shape: repeat_states\n",
      "(4, 32, -1, 128)\n",
      "Set input shape completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5158/635602852.py:12: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  h_shape = context.get_binding_shape(0)\n",
      "/tmp/ipykernel_5158/635602852.py:15: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(0, (batch_size, num_attention_heads, seq_len, dim))\n",
      "/tmp/ipykernel_5158/635602852.py:18: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  h_shape_2 = context.get_binding_shape(1)\n",
      "/tmp/ipykernel_5158/635602852.py:21: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(1, (batch_size, num_attention_heads, seq_len, dim))\n",
      "/tmp/ipykernel_5158/635602852.py:32: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(2), dtype=trt.nptype(engine.get_binding_dtype(2)))\n",
      "/tmp/ipykernel_5158/635602852.py:32: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(2), dtype=trt.nptype(engine.get_binding_dtype(2)))\n"
     ]
    }
   ],
   "source": [
    "trt_output = trt_inference(batch_size, config[\"num_heads\"], config[\"head_dim\"],\n",
    "                           trt_engineStr, \n",
    "                           h_state, h_state)\n",
    "\n",
    "trt_concat_states = trt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f1487e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 32, 90, 128]), (4, 32, 90, 128))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_key_states.shape, trt_concat_states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad89efb1",
   "metadata": {},
   "source": [
    "## Is the result valid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74abdd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(concat_key_states.clone().detach().cpu().numpy(), trt_concat_states, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb2d7299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1029,  0.4360,  1.7170,  ...,  1.0561,  0.6612,  0.4249],\n",
       "         [-0.1029,  0.4360,  1.7170,  ...,  1.0561,  0.6612,  0.4249],\n",
       "         [-0.1029,  0.4360,  1.7170,  ...,  1.0561,  0.6612,  0.4249],\n",
       "         ...,\n",
       "         [-0.1029,  0.4360,  1.7170,  ...,  1.0561,  0.6612,  0.4249],\n",
       "         [-0.1029,  0.4360,  1.7170,  ...,  1.0561,  0.6612,  0.4249],\n",
       "         [-0.1029,  0.4360,  1.7170,  ...,  1.0561,  0.6612,  0.4249]],\n",
       "\n",
       "        [[-1.0432, -0.3430,  0.2046,  ...,  0.0911,  0.0408,  0.0475],\n",
       "         [-1.0432, -0.3430,  0.2046,  ...,  0.0911,  0.0408,  0.0475],\n",
       "         [-1.0432, -0.3430,  0.2046,  ...,  0.0911,  0.0408,  0.0475],\n",
       "         ...,\n",
       "         [-1.0432, -0.3430,  0.2046,  ...,  0.0911,  0.0408,  0.0475],\n",
       "         [-1.0432, -0.3430,  0.2046,  ...,  0.0911,  0.0408,  0.0475],\n",
       "         [-1.0432, -0.3430,  0.2046,  ...,  0.0911,  0.0408,  0.0475]],\n",
       "\n",
       "        [[ 1.2805,  0.3576,  0.9282,  ...,  0.5669,  0.1782, -0.4079],\n",
       "         [ 1.2805,  0.3576,  0.9282,  ...,  0.5669,  0.1782, -0.4079],\n",
       "         [ 1.2805,  0.3576,  0.9282,  ...,  0.5669,  0.1782, -0.4079],\n",
       "         ...,\n",
       "         [ 1.2805,  0.3576,  0.9282,  ...,  0.5669,  0.1782, -0.4079],\n",
       "         [ 1.2805,  0.3576,  0.9282,  ...,  0.5669,  0.1782, -0.4079],\n",
       "         [ 1.2805,  0.3576,  0.9282,  ...,  0.5669,  0.1782, -0.4079]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3107,  1.5331, -0.7121,  ...,  0.4180, -0.4233,  0.2690],\n",
       "         [-0.3107,  1.5331, -0.7121,  ...,  0.4180, -0.4233,  0.2690],\n",
       "         [-0.3107,  1.5331, -0.7121,  ...,  0.4180, -0.4233,  0.2690],\n",
       "         ...,\n",
       "         [-0.3107,  1.5331, -0.7121,  ...,  0.4180, -0.4233,  0.2690],\n",
       "         [-0.3107,  1.5331, -0.7121,  ...,  0.4180, -0.4233,  0.2690],\n",
       "         [-0.3107,  1.5331, -0.7121,  ...,  0.4180, -0.4233,  0.2690]],\n",
       "\n",
       "        [[-0.0942,  0.1669, -0.2861,  ..., -0.6350, -0.3265, -0.0953],\n",
       "         [-0.0942,  0.1669, -0.2861,  ..., -0.6350, -0.3265, -0.0953],\n",
       "         [-0.0942,  0.1669, -0.2861,  ..., -0.6350, -0.3265, -0.0953],\n",
       "         ...,\n",
       "         [-0.0942,  0.1669, -0.2861,  ..., -0.6350, -0.3265, -0.0953],\n",
       "         [-0.0942,  0.1669, -0.2861,  ..., -0.6350, -0.3265, -0.0953],\n",
       "         [-0.0942,  0.1669, -0.2861,  ..., -0.6350, -0.3265, -0.0953]],\n",
       "\n",
       "        [[-0.5055, -0.2697, -0.2005,  ..., -0.2213, -0.5479,  0.8471],\n",
       "         [-0.5055, -0.2697, -0.2005,  ..., -0.2213, -0.5479,  0.8471],\n",
       "         [-0.5055, -0.2697, -0.2005,  ..., -0.2213, -0.5479,  0.8471],\n",
       "         ...,\n",
       "         [-0.5055, -0.2697, -0.2005,  ..., -0.2213, -0.5479,  0.8471],\n",
       "         [-0.5055, -0.2697, -0.2005,  ..., -0.2213, -0.5479,  0.8471],\n",
       "         [-0.5055, -0.2697, -0.2005,  ..., -0.2213, -0.5479,  0.8471]]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_key_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bf80da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.10292056,  0.4360279 ,  1.7169639 , ...,  1.0561283 ,\n",
       "          0.66121805,  0.424856  ],\n",
       "        [-0.10292056,  0.4360279 ,  1.7169639 , ...,  1.0561283 ,\n",
       "          0.66121805,  0.424856  ],\n",
       "        [-0.10292056,  0.4360279 ,  1.7169639 , ...,  1.0561283 ,\n",
       "          0.66121805,  0.424856  ],\n",
       "        ...,\n",
       "        [-0.10292089,  0.436028  ,  1.7169638 , ...,  1.0561281 ,\n",
       "          0.661218  ,  0.42485595],\n",
       "        [-0.10292089,  0.436028  ,  1.7169638 , ...,  1.0561281 ,\n",
       "          0.661218  ,  0.42485595],\n",
       "        [-0.10292089,  0.436028  ,  1.7169638 , ...,  1.0561281 ,\n",
       "          0.661218  ,  0.42485595]],\n",
       "\n",
       "       [[-1.0431769 , -0.34295708,  0.20461127, ...,  0.09106764,\n",
       "          0.04082745,  0.04753289],\n",
       "        [-1.0431769 , -0.34295708,  0.20461127, ...,  0.09106764,\n",
       "          0.04082745,  0.04753289],\n",
       "        [-1.0431769 , -0.34295708,  0.20461127, ...,  0.09106764,\n",
       "          0.04082745,  0.04753289],\n",
       "        ...,\n",
       "        [-1.0431767 , -0.3429572 ,  0.20461132, ...,  0.09106797,\n",
       "          0.04082736,  0.04753277],\n",
       "        [-1.0431767 , -0.3429572 ,  0.20461132, ...,  0.09106797,\n",
       "          0.04082736,  0.04753277],\n",
       "        [-1.0431767 , -0.3429572 ,  0.20461132, ...,  0.09106797,\n",
       "          0.04082736,  0.04753277]],\n",
       "\n",
       "       [[ 1.2805157 ,  0.35762554,  0.92821604, ...,  0.5669458 ,\n",
       "          0.17821947, -0.4078775 ],\n",
       "        [ 1.2805157 ,  0.35762554,  0.92821604, ...,  0.5669458 ,\n",
       "          0.17821947, -0.4078775 ],\n",
       "        [ 1.2805157 ,  0.35762554,  0.92821604, ...,  0.5669458 ,\n",
       "          0.17821947, -0.4078775 ],\n",
       "        ...,\n",
       "        [ 1.2805154 ,  0.35762554,  0.9282161 , ...,  0.5669457 ,\n",
       "          0.1782195 , -0.40787745],\n",
       "        [ 1.2805154 ,  0.35762554,  0.9282161 , ...,  0.5669457 ,\n",
       "          0.1782195 , -0.40787745],\n",
       "        [ 1.2805154 ,  0.35762554,  0.9282161 , ...,  0.5669457 ,\n",
       "          0.1782195 , -0.40787745]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.31068653,  1.5330731 , -0.7120719 , ...,  0.41795957,\n",
       "         -0.42326495,  0.26902154],\n",
       "        [-0.31068653,  1.5330731 , -0.7120719 , ...,  0.41795957,\n",
       "         -0.42326495,  0.26902154],\n",
       "        [-0.31068653,  1.5330731 , -0.7120719 , ...,  0.41795957,\n",
       "         -0.42326495,  0.26902154],\n",
       "        ...,\n",
       "        [-0.31068647,  1.5330727 , -0.7120719 , ...,  0.41795948,\n",
       "         -0.42326465,  0.26902163],\n",
       "        [-0.31068647,  1.5330727 , -0.7120719 , ...,  0.41795948,\n",
       "         -0.42326465,  0.26902163],\n",
       "        [-0.31068647,  1.5330727 , -0.7120719 , ...,  0.41795948,\n",
       "         -0.42326465,  0.26902163]],\n",
       "\n",
       "       [[-0.09416142,  0.16691136, -0.28611252, ..., -0.6349699 ,\n",
       "         -0.3265326 , -0.09525649],\n",
       "        [-0.09416142,  0.16691136, -0.28611252, ..., -0.6349699 ,\n",
       "         -0.3265326 , -0.09525649],\n",
       "        [-0.09416142,  0.16691136, -0.28611252, ..., -0.6349699 ,\n",
       "         -0.3265326 , -0.09525649],\n",
       "        ...,\n",
       "        [-0.09416144,  0.16691154, -0.28611246, ..., -0.6349697 ,\n",
       "         -0.32653242, -0.09525666],\n",
       "        [-0.09416144,  0.16691154, -0.28611246, ..., -0.6349697 ,\n",
       "         -0.32653242, -0.09525666],\n",
       "        [-0.09416144,  0.16691154, -0.28611246, ..., -0.6349697 ,\n",
       "         -0.32653242, -0.09525666]],\n",
       "\n",
       "       [[-0.50552785, -0.26971328, -0.20054695, ..., -0.22129643,\n",
       "         -0.54794306,  0.8470512 ],\n",
       "        [-0.50552785, -0.26971328, -0.20054695, ..., -0.22129643,\n",
       "         -0.54794306,  0.8470512 ],\n",
       "        [-0.50552785, -0.26971328, -0.20054695, ..., -0.22129643,\n",
       "         -0.54794306,  0.8470512 ],\n",
       "        ...,\n",
       "        [-0.5055281 , -0.26971316, -0.2005471 , ..., -0.22129641,\n",
       "         -0.54794294,  0.84705114],\n",
       "        [-0.5055281 , -0.26971316, -0.2005471 , ..., -0.22129641,\n",
       "         -0.54794294,  0.84705114],\n",
       "        [-0.5055281 , -0.26971316, -0.2005471 , ..., -0.22129641,\n",
       "         -0.54794294,  0.84705114]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_concat_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c84b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
