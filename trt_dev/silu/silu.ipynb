{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c49224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cuda import cudart\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import tensorrt as trt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b055b5",
   "metadata": {},
   "source": [
    "## Generate input and data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5938a225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputH0 : (1, 2, 2)\n",
      "[[[0. 1.]\n",
      "  [2. 3.]]]\n"
     ]
    }
   ],
   "source": [
    "# Input tensor shape NCHW\n",
    "nIn, hIn, wIn = 1, 2, 2\n",
    "\n",
    "# Output tensor shape C\n",
    "cOut = 2\n",
    "\n",
    "# Input tensor\n",
    "data = np.arange(hIn * wIn, dtype=np.float32).reshape(nIn, hIn, wIn)\n",
    "\n",
    "# fully connected weight\n",
    "weight = np.ones(cOut * hIn * wIn, dtype=np.float32).reshape(cOut, hIn * wIn)\n",
    "\n",
    "# fully connected bias\n",
    "bias = np.zeros(cOut, dtype=np.float32)\n",
    "\n",
    "print(\"inputH0 :\", data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f0a32f",
   "metadata": {},
   "source": [
    "## torch silu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fcb9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiLUActivation(nn.Module):\n",
    "    \"\"\"\n",
    "    See Gaussian Error Linear Units (Hendrycks et al., https://arxiv.org/abs/1606.08415) where the SiLU (Sigmoid Linear\n",
    "    Unit) was originally introduced and coined, and see Sigmoid-Weighted Linear Units for Neural Network Function\n",
    "    Approximation in Reinforcement Learning (Elfwing et al., https://arxiv.org/abs/1702.03118) and Swish: a Self-Gated\n",
    "    Activation Function (Ramachandran et al., https://arxiv.org/abs/1710.05941v1) where the SiLU was experimented with\n",
    "    later.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return nn.functional.silu(input)\n",
    "    \n",
    "    def b_forward(self, input: Tensor) -> Tensor:\n",
    "        return torch.matmul(input.T, nn.functional.sigmoid(input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f319bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_torch(nIn, hIn, wIn, cOut, raw_data, weight, bias):\n",
    "    data = torch.tensor(raw_data).reshape(-1)\n",
    "    # model = torch.nn.Linear(hIn * wIn, cOut)\n",
    "\n",
    "    # # initialize model weights\n",
    "    # model.weight.data.fill_(1)\n",
    "    # print(model.weight.data.detach().cpu().numpy())\n",
    "    # model.bias.data.fill_(0)\n",
    "    model = SiLUActivation()\n",
    "\n",
    "    output = model(data)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a791092",
   "metadata": {},
   "source": [
    "## Test torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9de4d00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_torch : torch.Size([4])\n",
      "tensor([0.0000, 0.7311, 1.7616, 2.8577])\n"
     ]
    }
   ],
   "source": [
    "torch_output = test_torch(nIn, hIn, wIn, cOut, data, weight, bias)\n",
    "print(\"output_torch :\", torch_output.shape)\n",
    "print(torch_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a75c1d",
   "metadata": {},
   "source": [
    "## tensorRT SiLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca70c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_create(nIn, hIn, cOut, weight, bias):\n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    builder = trt.Builder(logger)\n",
    "\n",
    "    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "    config = builder.create_builder_config()\n",
    "\n",
    "    # input\n",
    "    inputT0 = network.add_input('inputT0', trt.DataType.FLOAT, (nIn, -1, hIn))\n",
    "\n",
    "    # dynamic shape optimization\n",
    "    profile = builder.create_optimization_profile();\n",
    "    profile.set_shape(\"inputT0\", (nIn, 1, hIn), (nIn, 2, hIn), (nIn, 3, hIn)) \n",
    "    config.add_optimization_profile(profile)\n",
    "\n",
    "    # add fully connected layer\n",
    "    selu_sigmoid_layer = network.add_activation(inputT0, type=trt.ActivationType.SIGMOID)\n",
    "    selu_mult_layer = network.add_elementwise(inputT0, selu_sigmoid_layer.get_output(0), op=trt.ElementWiseOperation.PROD)\n",
    "\n",
    "    # output\n",
    "    network.mark_output(selu_mult_layer.get_output(0))\n",
    "\n",
    "    engineString = builder.build_serialized_network(network, config)\n",
    "    \n",
    "    return engineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14e9aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_engineStr = trt_create(nIn, hIn, cOut, weight, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aff1586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_inference(nIn, hIn, cOut, engineString, raw_data):\n",
    "    print(engineString)\n",
    "    print(\"Runtime\")\n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    engine = trt.Runtime(logger).deserialize_cuda_engine(engineString)\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    # dynamic shape configure\n",
    "    print(\"Set input shape\")\n",
    "    context.set_input_shape(\"inputT0\", (nIn, 2, hIn))\n",
    "    context.set_binding_shape(0, (nIn, 2, hIn))\n",
    "    origin_inputshape = context.get_binding_shape(0)\n",
    "\n",
    "    print(\"Set input shape completed\")\n",
    "\n",
    "    data = np.array(raw_data)\n",
    "\n",
    "    _, stream = cudart.cudaStreamCreate()\n",
    "    print(\"Reshaping\")\n",
    "\n",
    "    inputH0 = np.ascontiguousarray(data.reshape(-1))\n",
    "    outputH0 = np.empty(context.get_binding_shape(1), dtype=trt.nptype(engine.get_binding_dtype(1)))\n",
    "    print(\"Reshaped\")\n",
    "\n",
    "    # initialize input and output data\n",
    "    _, inputD0 = cudart.cudaMallocAsync(inputH0.nbytes, stream)\n",
    "    _, outputD0 = cudart.cudaMallocAsync(outputH0.nbytes, stream)\n",
    "\n",
    "    # move input to device\n",
    "    cudart.cudaMemcpyAsync(inputD0, inputH0.ctypes.data, inputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n",
    "\n",
    "    # execute\n",
    "    print(\"execute\")\n",
    "    context.execute_async_v2([int(inputD0), int(outputD0)], stream)\n",
    "\n",
    "    # move output back to host\n",
    "    cudart.cudaMemcpyAsync(outputH0.ctypes.data, outputD0, outputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost, stream)\n",
    "\n",
    "    # wait for everything\n",
    "    cudart.cudaStreamSynchronize(stream)\n",
    "\n",
    "    cudart.cudaStreamDestroy(stream)\n",
    "    cudart.cudaFree(inputD0)\n",
    "    cudart.cudaFree(outputD0)\n",
    "\n",
    "    return outputH0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52e7b62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorrt.tensorrt.IHostMemory object at 0x7f08447a4730>\n",
      "Runtime\n",
      "Set input shape\n",
      "Set input shape completed\n",
      "Reshaping\n",
      "Reshaped\n",
      "execute\n",
      "output_trt : (4,)\n",
      "[0.        0.7310586 1.7615942 2.8577223]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25334/3070280412.py:11: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(0, (nIn, 2, hIn))\n",
      "/tmp/ipykernel_25334/3070280412.py:12: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  origin_inputshape = context.get_binding_shape(0)\n",
      "/tmp/ipykernel_25334/3070280412.py:22: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(1), dtype=trt.nptype(engine.get_binding_dtype(1)))\n",
      "/tmp/ipykernel_25334/3070280412.py:22: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(1), dtype=trt.nptype(engine.get_binding_dtype(1)))\n"
     ]
    }
   ],
   "source": [
    "trt_output = trt_inference(nIn, hIn, cOut, trt_engineStr, data)\n",
    "trt_output = trt_output.reshape(-1)\n",
    "print(\"output_trt :\", trt_output.shape)\n",
    "print(trt_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b852ef83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 20 06:44:58 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   51C    P0    42W / 250W |    312MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  On   | 00000000:5E:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    25W / 250W |      4MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-PCIE...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    26W / 250W |      4MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-PCIE...  On   | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    27W / 250W |      4MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6692ff35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
